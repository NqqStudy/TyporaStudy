# 1 C++面试宝典 — SQL

## 1.1 介绍一下数据库分页

### 1.1.1 MySQL 分页语法

- 在MySQL中，SELECT语句默认返回所有匹配的行，它们可能是指定表中的每个行。为了返回第一行或前几行，可使用LIMIT子句，以实现分页查询。**LIMIT子句的语法**如下：

```
-- 在所有的查询结果中，返回前5行记录。 
SELECT prod_name FROM products LIMIT 5; 
-- 在所有的查询结果中，从第5行开始，返回5行记录
SELECT prod_name FROM products LIMIT 5,5;
```

- 带一个值的LIMIT总是从第一行开始，给出的数为返回的行数。带两个值的LIMIT可以指定从行号为第一个值的位置开始

### 1.1.2 优化LIMIT分页

- 在偏移量非常大的时候，例如 LIMIT 10000,20 这样的查询，这时MySQL需要查询10020条记录然后只返回最后20条，前面的10000条记录都将被抛弃，这样的代价是非常高的。如果所有的页面被访问的频率都相同，那么这样的查询平均需要访问半个表的数据。**要优化这种查询，要么是在页面中限制分页的数量，要么是优化大偏移量的性能**
- **优化此类分页查询的一个最简单的办法就是尽可能地使用索引覆盖扫描，而不是查询所有的列，然后根据需要做一次关联操作再返回所需的列**。对于偏移量很大的时候，这样做的效率会提升非常大。考虑下面的查询：

```
SELECT film_id,description FROM sakila.film ORDER BY title LIMIT 50,5;
```

- 如果这个表非常大，那么这个查询最好改写成下面的样子

```
SELECT film.film_id,film.description  FROM sakila.film INNER JOIN (SELECT film_id FROM sakila.film ORDER BY title LIMIT 50,5 ) AS lim USING(film_id);
```

- 这里的“延迟关联”将大大提升查询效率，它**让MySQL扫描尽可能少的页面，获取需要访问的记录后再根据关联列回原表查询需要的所有列**。这个技术也可以用于优化关联查询中的LIMIT子句
- 有时候也可以将LIMIT查询转换为已知位置的查询，让MySQL通过范围扫描获得对应的结果。例如，如果在一个位置列上有索引，并且预先计算出了边界值，上面的查询就可以改写为：

```
SELECT film_id,description FROM skila.film WHERE position BETWEEN 50 AND 54 ORDER BY position;
```

- 对数据进行排名的问题也与此类似，但往往还会同时和GROUP BY混合使用，在这种情况下通常都需要预先计算并存储排名信息
- LIMIT和OFFSET的问题，其实是OFFSET的问题，它会导致MySQL扫描大量不需要的行然后再抛弃掉。如果可以使用书签记录上次取数的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用OFFSET。例如，若需要按照租赁记录做翻页，那么可以根据最新一条租赁记录向后追溯，这种做法可行是因为租赁记录的主键是单调增长的。首先使用下面的查询获得第一组结果：

```
SELECT * FROM sakila.rental ORDER BY rental_id DESC LIMIT 20;
```

- 假设上面的查询返回的是主键16049到16030的租赁记录，那么下一页查询就可以从16030这个点开始：

```
SELECT * FROM sakila.rental  WHERE rental_id < 16030 ORDER BY rental_id DESC LIMIT 20;
```

该技术的好处是无论翻页到多么后面，其性能都会很好。

## 1.2 介绍一下SQL中的聚合函数

常用的聚合函数有**COUNT()、AVG()、SUM()、MAX()、MIN()**，下面以MySQL为例，说明这些函数的作用。

1. **COUNT()函数**

**COUNT()函数统计数据表中包含的记录行的总数，或者根据查询结果返回列中包含的数据行数**，它有两种用法：

- COUNT(*)计算表中总的行数，不管某列是否有数值或者为空值
- COUNT(字段名)计算指定列下总的行数，计算时将忽略空值的行

COUNT()函数可以与GROUP BY一起使用来计算每个分组的总和

2. **AVG()函数**

- AVG()函数通过计算返回的行数和每一行数据的和，求得指定列数据的平均值
- AVG()函数可以与GROUP BY一起使用，来计算每个分组的平均值

3. **SUM()函数**

- SUM()是一个求总和的函数，返回**指定列值的总和**
- SUM()可以与GROUP BY一起使用，来计算每个分组的总和

4. **MAX()函数**

- MAX()返回指定列中的最大值
- MAX()也可以和GROUP BY关键字一起使用，求每个分组中的最大值
- MAX()函数不仅适用于查找数值类型，也可应用于字符类型

5. **MIN()函数**

- MIN()返回查询列中的最小值
- MIN()也可以和GROUP BY关键字一起使用，求出每个分组中的最小值
- MIN()函数与MAX()函数类似，不仅适用于查找数值类型，也可应用于字符类型

## 1.3 表跟表是怎么关联的？

**表与表之间常用的关联方式**有两种：**内连接、外连接**，下面以MySQL为例来说明这两种连接方式

内连接

- 内连接通过**INNER JOIN**来实现，它将**返回两张表中满足连接条件的数据，不满足条件的数据不会查询出来**

外连接

- 外连接通过**OUTER JOIN**来实现，它会返回两张表中满足连接条件的数据，同时返回不满足连接条件的数据。外连接有两种形式：左外连接（LEFT OUTER JOIN）、右外连接（RIGHT OUTER JOIN）

- **左外连接**：可以简称为左连接（LEFT JOIN），它会返回左表中的所有记录和右表中满足连接条件的记录
- **右外连接**：可以简称为右连接（RIGHT JOIN），它会返回右表中的所有记录和左表中满足连接条件的记录

除此之外，还有一种常见的连接方式：**等值连接**。这种连接是通过WHERE子句中的条件，将两张表连接在一起，它的实际效果等同于内连接。出于语义清晰的考虑，一般更建议使用内连接，而不是等值连接。

以上是从语法上来说明表与表之间关联的实现方式，而从表的关系上来说，比较常见的关联关系有：**一对多关联、多对多关联、自关联**

- 一对多关联：这种关联形式最为常见，一般是两张表具有主从关系，并且以主表的主键关联从表的外键来实现这种关联关系。另外，以从表的角度来看，它们是具有多对一关系的，所以不再赘述多对一关联
- 多对多关联：这种关联关系比较复杂，如果两张表具有多对多的关系，那么它们之间需要有一张中间表来作为衔接，以实现这种关联关系。这个中间表要设计两列，分别存储那两张表的主键。因此，这两张表中的任何一方，都与中间表形成了一对多关系，从而在这个中间表上建立起了多对多关系
- 自关联：自关联就是一张表自己与自己相关联，为了避免表名的冲突，需要在关联时通过别名将它们当做两张表来看待。一般在表中数据具有层级（树状）时，可以采用自关联一次性查询出多层级的数据

## 1.4 对外连接的了解

外连接通过OUTER JOIN来实现，它会返回两张表中满足连接条件的数据，同时返回不满足连接条件的数据。常见的外连接有两种形式：**左外连接(LEFT OUTER JOIN)、右外连接(RIGHT OUTER JOIN)**

- 左外连接：可以简称为左连接（LEFT JOIN），它会返回**左表中的所有记录和右表中满足连接条件的记录**
- 右外连接：可以简称为右连接（RIGHT JOIN），它会返回**右表中的所有记录和左表中满足连接条件的记录**

实际上，外连接还有一种形式：**完全外连接(FULL OUTER JOIN)**，但MySQL不支持这种形式

## 1.5 数据库的左连接和右连接

外连接通过OUTER JOIN来实现，它会返回两张表中满足连接条件的数据，同时返回不满足连接条件的数据。常见的外连接有两种形式：左外连接(LEFT OUTER JOIN)、右外连接(RIGHT OUTER JOIN)

- 左外连接：可以简称为左连接（LEFT JOIN），它会返回左表中的所有记录和右表中满足连接条件的记录。
- 右外连接：可以简称为右连接（RIGHT JOIN），它会返回右表中的所有记录和左表中满足连接条件的记录。

## 1.6 SQL中怎么将行转成列？

我们以MySQL数据库为例，来说明行转列的实现方式

首先，假设我们有一张分数表（tb_score），表中的数据如下图：

![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789565340/54AFB38EE7925F020B8244A971AD0197)

然后，我们再来看一下转换之后需要得到的结果，如下图：

![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789578254/4D7E0B1F85854406C0011E8D87BD5BBB)

可以看出，这里**行转列是将原来的subject字段的多行内容选出来，作为结果集中的不同列，并根据userid进行分组显示对应的score**。通常，我们有两种方式来实现这种转换

1. 使用 CASE...WHEN...THEN 语句实现行转列，参考如下代码：

   ```
   SELECT userid, SUM(CASE `subject` WHEN '语文' THEN score ELSE 0 END) as '语文', SUM(CASE `subject` WHEN '数学' THEN score ELSE 0 END) as '数学', SUM(CASE `subject` WHEN '英语' THEN score ELSE 0 END) as '英语', SUM(CASE `subject` WHEN '政治' THEN score ELSE 0 END) as '政治'  FROM tb_score  GROUP BY userid
   ```

   注意，SUM() 是为了能够使用GROUP BY根据userid进行分组，因为每一个userid对应的subject="语文"的记录只有一条，所以SUM() 的值就等于对应那一条记录的score的值。假如userid ='001' and subject='语文' 的记录有两条，则此时SUM() 的值将会是这两条记录的和，同理，使用Max()的值将会是这两条记录里面值最大的一个。但是正常情况下，一个user对应一个subject只有一个分数，因此可以使用SUM()、MAX()、MIN()、AVG()等聚合函数都可以达到行转列的效果。

2. 使用 IF() 函数实现行转列，参考如下代码：

   ```
   SELECT userid, SUM(IF(`subject`='语文',score,0)) as '语文', SUM(IF(`subject`='数学',score,0)) as '数学', SUM(IF(`subject`='英语',score,0)) as '英语', SUM(IF(`subject`='政治',score,0)) as '政治'  FROM tb_score  GROUP BY userid
   ```

   注意，IF(subject='语文',score,0) 作为条件，即对所有subject='语文'的记录的score字段进行SUM()、MAX()、MIN()、AVG()操作，如果score没有值则默认为0

## 1.7 对SQL注入的理解

- **SQL注入的原理是将SQL代码伪装到输入参数中，传递到服务器解析并执行的一种攻击手法**。就是说，在一些对SERVER端发起的请求参数中植入一些SQL代码，SERVER端在执行SQL操作时，会拼接对应参数，同时也将一些SQL注入攻击的“SQL”拼接起来，导致会执行一些预期之外的操作

举个例子：

比如我们的登录功能，其登录界面包括用户名和密码输入框以及提交按钮，登录时需要输入用户名和密码，然后提交。此时调用接口/user/login/ 加上参数username、password，首先连接数据库，然后后台对请求参数中携带的用户名、密码进行参数校验，即SQL的查询过程。假设正确的用户名和密码为ls和123456，输入正确的用户名和密码、提交，相当于调用了以下的SQL语句

```
SELECT * FROM user WHERE username = 'ls' AND password = '123456'
```

SQL中会将#及--以后的字符串当做注释处理，如果我们使用 ' or 1=1 # 作为用户名参数，那么服务端构建的SQL语句就如下：

```
select * from user where username='' or 1=1 #' and password='123456'
```

而#会忽略后面的语句，而1=1属于常等型条件，因此这个SQL将查询出所有的登录用户。其实上面的SQL注入只是在参数层面做了些手脚，如果是引入了一些功能性的SQL那就更危险了，比如上面的登录功能，如果用户名使用这个 ' or 1=1;delete * from users; #，那么在";"之后相当于是另外一条新的SQL，这个SQL是删除全表，是非常危险的操作，因此SQL注入这种还是需要特别注意的。

如何解决SQL注入

1. **严格的参数校验**

   参数校验就没得说了，在一些不该有特殊字符的参数中提前进行特殊字符校验即可

2. **SQL预编译**

   在知道SQL注入的原理之后，我们同样也了解到MySQL有预编译的功能，指的是在服务器启动时，MySQL Client把SQL语句的模板（变量采用占位符进行占位）发送给MySQL服务器，MySQL服务器对SQL语句的模板进行编译，编译之后根据语句的优化分析对相应的索引进行优化，在最终绑定参数时把相应的参数传送给MySQL服务器，直接进行执行，节省了SQL查询时间，以及MySQL服务器的资源，达到一次编译、多次执行的目的，除此之外，还可以防止SQL注入

   具体是怎样防止SQL注入的呢？实际上当将绑定的参数传到MySQL服务器，MySQL服务器对参数进行编译，即填充到相应的占位符的过程中，做了转义操作。我们常用的JDBC就有预编译功能，不仅提升性能，而且防止SQL注入

## 1.8 将一张表的部分数据更新到另一张表，该如何操作呢？

可以采用关联更新的方式，将一张表的部分数据，更新到另一张表内。参考如下代码：

```
update b set b.col=a.col from a,b where a.id=b.id;
update b set col=a.col from b inner join a on a.id=b.id;
update b set b.col=a.col from b left Join a on b.id = a.id;
```

## 1.9 WHERE和HAVING有什么区别？

- WHERE是一个约束声明，使用WHERE约束来自数据库的数据，WHERE是在结果返回之前起作用的，WHERE中不能使用聚合函数
- HAVING是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在HAVING中可以使用聚合函数。另一方面，HAVING子句中不能使用除了分组字段和聚合函数之外的其他字段
- 从性能的角度来说，HAVING子句中如果使用了分组字段作为过滤条件，应该替换成WHERE子句。因为WHERE可以在执行分组操作和计算聚合函数之前过滤掉不需要的数据，性能会更好

# 2 C++面试宝典 — 事务

## 2.1 说说对数据库事务的了解

**事务可由一条非常简单的SQL语句组成，也可以由一组复杂的SQL语句组成**。在事务中的操作，要么都执行修改，要么都不执行，这就是事务的目的，也是事务模型区别于文件系统的重要特征之一

事务需遵循ACID四个特性：

- **A（atomicity），原子性**：原子性指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功，整个事务的执行才算成功。事务中任何一个SQL语句执行失败，那么已经执行成功的SQL语句也必须撤销，数据库状态应该退回到执行事务前的状态
- **C（consistency），一致性**：一致性指事务将数据库从一种状态转变为另一种一致的状态。在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏
- **I（isolation），隔离性**：事务的隔离性要求每个读写事务的对象与其他事务的操作对象能相互分离，即该事务提交前对其他事务都不可见，这通常使用锁来实现
- **D（durability），持久性**：事务一旦提交，其结果就是永久性的，即使发生宕机等故障，数据库也能将数据恢复。持久性保证的是事务系统的高可靠性，而不是高可用性

事务可以分为以下几种类型：

- **扁平事务**：是事务类型中最简单的一种，而在实际生产环境中，这可能是使用最为频繁的事务。在扁平事务中，所有操作都处于同一层次，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束。处于之间的操作是原子的，要么都执行，要么都回滚
- **带有保存点的扁平事务**：除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态，这是因为可能某些事务在执行过程中出现的错误并不会对所有的操作都无效，放弃整个事务不合乎要求，开销也太大。保存点（savepoint）用来通知系统应该记住事务当前的状态，以便以后发生错误时，事务能回到该状态
- **链事务**：可视为保存点模式的一个变种。链事务的思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。注意，提交事务操作和开始下一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的
- **嵌套事务**：是一个层次结构框架。有一个顶层事务（top-level transaction）控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务（subtransaction），其控制每一个局部的变换
- **分布式事务**：通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。对于分布式事务，同样需要满足ACID特性，要么都发生，要么都失效

对于MySQL的InnoDB存储引擎来说，它支持扁平事务、带有保存点的扁平事务、链事务、分布式事务。对于嵌套事务，MySQL数据库并不是原生的，因此对于有并行事务需求的用户来说MySQL就无能为力了，但是用户可以通过带有保存点的事务来模拟串行的嵌套事务

## 2.2 事务有哪几种类型，它们之间有什么区别？

事务可以分为以下几种类型：

- **扁平事务**：是事务类型中最简单的一种，而在实际生产环境中，这可能是使用最为频繁的事务。在扁平事务中，所有操作都处于同一层次，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束。处于之间的操作是原子的，要么都执行，要么都回滚
- **带有保存点的扁平事务**：除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态，这是因为可能某些事务在执行过程中出现的错误并不会对所有的操作都无效，放弃整个事务不合乎要求，开销也太大。保存点（savepoint）用来通知系统应该记住事务当前的状态，以便以后发生错误时，事务能回到该状态
- **链事务**：可视为保存点模式的一个变种。链事务的思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。注意，提交事务操作和开始下一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的
- **嵌套事务**：是一个层次结构框架。有一个顶层事务（top-level transaction）控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务（subtransaction），其控制每一个局部的变换
- **分布式事务**：通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。对于分布式事务，同样需要满足ACID特性，要么都发生，要么都失效

对于MySQL的InnoDB存储引擎来说，它支持扁平事务、带有保存点的扁平事务、链事务、分布式事务。对于嵌套事务，MySQL数据库并不是原生的，因此对于有并行事务需求的用户来说MySQL就无能为力了，但是用户可以通过带有保存点的事务来模拟串行的嵌套事务。

## 2.3 MySQL的ACID特性分别是怎么实现的(重点)

- **原子性实现原理**

实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的sql语句。InnoDB实现回滚靠的是undo log，当事务对数据库进行修改时，InnoDB会生成对应的undo log。如果事务执行失败或调用rollback，导致事务需要回滚，便可以利用undo log的信息将数据回滚到修改之前的样子

undo log属于逻辑日志，它记录的是sql执行相关的信息。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作。对于insert，回滚时会执行delete。对于delete，回滚时会执行insert。对于update，回滚时则会执行相反的update，把数据改回去

- **持久性实现原理**

InnoDB作为MySQL的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘IO，效率会很低。为此**InnoDB提供缓存(Buffer Pool)**，Buffer Pool中包含磁盘中部分数据页的映射，作为访问数据库的缓冲。当从数据库读取数据时，会首先从Buffer Pool中读取，如果Buffer Pool中没有，则从磁盘读取后放入Buffer Pool。当向数据库写入数据时，会首先写入Buffer Pool，**Buffer Pool中修改的数据会定期刷新到磁盘中(这一过程称为刷脏)**

Buffer Pool的使用大大提高读写数据的效率，但是也带了新的问题：**如果MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证**

于是，redo log被引入来解决这个问题。当数据修改时，除了修改Buffer Pool中的数据，还会在redo log记录这次操作。当事务提交时，会调用fsync接口对redo log进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log采用的是WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足持久性要求

既然redo log也需要在事务提交时将日志写入磁盘，为什么它比直接将Buffer Pool中修改的数据写入磁盘(即刷脏)要快呢？主要有以下两方面的原因：

- 刷脏是随机IO，因为每次修改的数据位置随机，但写redo log是追加操作，属于顺序IO
- 刷脏是以数据页（Page）为单位的，MySQL默认页大小是16KB，一个Page上一个小修改都要整页写入。而redo log中只包含真正需要写入的部分，无效IO大大减少

- **隔离性实现原理**

隔离性追求的是并发情形下事务之间互不干扰。简单起见，我们主要考虑最简单的读操作和写操作(加锁读等特殊读操作会特殊说明)，那么隔离性的探讨，主要可以分为两个方面

第一方面，(一个事务)写操作对(另一个事务)写操作的影响：**锁机制保证隔离性**

隔离性要求同一时刻只能有一个事务对数据进行写操作，InnoDB通过锁机制来保证这一点。锁机制的基本原理可以概括为：事务在修改数据之前，需要先获得相应的锁。获得锁之后，事务便可以修改数据。该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁

按照粒度，锁可以分为表锁、行锁以及其他位于二者之间的锁。表锁在操作数据时会锁定整张表，并发性能较差。行锁则只锁定需要操作的数据，并发性能好。但是由于加锁本身需要消耗资源，因此在锁定数据较多情况下使用表锁可以节省大量资源。MySQL中不同的存储引擎支持的锁是不一样的，例如MyIsam只支持表锁，而InnoDB同时支持表锁和行锁，且出于性能考虑，绝大多数情况下使用的都是行锁

第二方面，(一个事务)写操作对(另一个事务)读操作的影响：**MVCC保证隔离性**

InnoDB默认的隔离级别是RR（REPEATABLE READ），RR解决脏读、不可重复读、幻读等问题，使用的是MVCC。MVCC全称Multi-Version Concurrency Control，即多版本的并发控制协议。它最大的优点是读不加锁，因此读写不冲突，并发性能好。InnoDB实现MVCC，多个版本的数据可以共存，主要基于以下技术及数据结构：

1. 隐藏列：InnoDB中每行数据都有隐藏列，隐藏列中包含了本行数据的事务id、指向undo log的指针等
2. 基于undo log的版本链：每行数据的隐藏列中包含了指向undo log的指针，而每条undo log也会指向更早版本的undo log，从而形成一条版本链
3. ReadView：通过隐藏列和版本链，MySQL可以将数据恢复到指定版本。但是具体要恢复到哪个版本，则需要根据ReadView来确定。所谓ReadView，是指事务（记做事务A）在某一时刻给整个事务系统（trx_sys）打快照，之后再进行读操作时，会将读取到的数据中的事务id与trx_sys快照比较，从而判断数据对该ReadView是否可见，即对事务A是否可见

- **一致性实现原理**

可以说，一致性是事务追求的最终目标。前面提到的原子性、持久性和隔离性，都是为了保证数据库状态的一致性。此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。实现一致性的措施包括：

- 保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证
- 数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等
- 应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致

## 2.4 MySQL的事务隔离级别

SQL 标准定义四种隔离级别，这四种隔离级别分别是：

- **读未提交**(READ UNCOMMITTED)
- **读提交** (READ COMMITTED)
- **可重复读** (REPEATABLE READ)
- **串行化** (SERIALIZABLE)

事务隔离是为了解决脏读、不可重复读、幻读问题，下表展示4 种隔离级别对这三个问题的解决程度：

|     隔离级别     |  脏读  | 不可重复读 |  幻读  |
| :--------------: | :----: | :--------: | :----: |
| READ UNCOMMITTED |  可能  |    可能    |  可能  |
|  READ COMMITTED  | 不可能 |    可能    |  可能  |
| REPEATABLE READ  | 不可能 |   不可能   |  可能  |
|   SERIALIZABLE   | 不可能 |   不可能   | 不可能 |

上述4种隔离级别MySQL都支持，并且InnoDB存储引擎默认的支持隔离级别是REPEATABLE READ，但是与标准SQL不同的是，InnoDB存储引擎在REPEATABLE READ事务隔离级别下，使用Next-Key Lock的锁算法，因此避免了幻读的产生。所以，InnoDB存储引擎在默认的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL标准的SERIALIZABLE隔离级别

并发情况下，读操作可能存在的三类问题：

1. 脏读：当前事务(A)中可以读到其他事务(B)未提交的数据（脏数据），这种现象是脏读
2. 不可重复读：在事务A中先后两次读取同一个数据，两次读取的结果不一样，这种现象称为不可重复读。脏读与不可重复读的区别在于：前者读到的是其他事务未提交的数据，后者读到的是其他事务已提交的数据
3. 幻读：在事务A中按照某个条件先后两次查询数据库，两次查询结果的条数不同，这种现象称为幻读。不可重复读与幻读的区别可以通俗的理解为：前者是数据变了，后者是数据的行数变了

## 2.5 MySQL的事务隔离级别是怎么实现的？

InnoDB支持四种隔离级别，每种级别解决掉的问题如下表：

|                         | 脏读 | 不可重复读幻读 | 幻读 |
| :---------------------: | :--: | :------------: | :--: |
|    READ UNCOMMITTED     |  Y   |       Y        |  Y   |
|     READ COMMITTED      |  N   |       Y        |  Y   |
| REPEATABLE READ（默认） |  N   |       N        |  N   |
|      SERIALIZABLE       |  N   |       N        |  N   |

这四种隔离级别的实现机制如下：

1. **READ UNCOMMITTED & READ COMMITTED**

   通过Record Lock算法实现行锁，但READ UNCOMMITTED允许读取未提交数据，所以存在脏读问题。而READ COMMITTED允许读取提交数据，所以不存在脏读问题，但存在不可重复读问题

2. **REPEATABLE READ**

   使用Next-Key Lock算法实现了行锁，并且不允许读取已提交的数据，所以解决了不可重复读的问题。另外，该算法包含间隙锁，会锁定一个范围，因此也解决幻读的问题

3. **SERIALIZABLE**

   对每个SELECT语句后自动加上LOCK IN SHARE MODE，即为每个读取操作加一个共享锁。因此在这个事务隔离级别下，读占用锁，对一致性的非锁定读不再予以支持

## 2.6 事务可以嵌套吗？

- 可以，因为嵌套事务也是众多事务分类中的一种，它是一个层次结构框架。有一个顶层事务控制着各个层次的事务，顶层事务之下嵌套的事务被称为子事务，它控制每一个局部的变换
- 需要注意的是，MySQL数据库不支持嵌套事务

## 2.7 如何实现可重复读？

- MySQL的InnoDB引擎，在默认的REPEATABLE READ的隔离级别下，实现可重复读，同时也解决幻读问题。它使用Next-Key Lock算法实现了行锁，并且不允许读取已提交的数据，所以解决不可重复读的问题。另外，该算法包含间隙锁，会锁定一个范围，因此也解决幻读的问题

## 2.8 如何解决幻读问题？

MySQL的InnoDB引擎，在默认的REPEATABLE READ的隔离级别下，实现了可重复读，同时也解决了幻读问题。它使用Next-Key Lock算法实现了行锁，并且不允许读取已提交的数据，所以解决了不可重复读的问题。另外，该算法包含了间隙锁，会锁定一个范围，因此也解决幻读的问题

## 2.9 MySQL事务如何回滚？

在MySQL默认的配置下，事务都是自动提交和回滚的。当显示地开启一个事务时，可以使用ROLLBACK语句进行回滚。该语句有两种用法：

- **ROLLBACK**：要使用这个语句的最简形式，只需发出ROLLBACK。同样地，也可以写为ROLLBACK WORK，但是二者几乎是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改
- **ROLLBACK TO [SAVEPOINT] identifier** ：这个语句与SAVEPOINT命令一起使用。可以把事务回滚到标记点，而不回滚在此标记点之前的任何工作

# 3 C++面试宝典 — 锁/优化/其他

## 3.1 了解数据库的锁吗？

锁是数据库系统区别于文件系统的一个关键特性，锁机制用于管理对共享资源的并发访问。下面我们以MySQL数据库的InnoDB引擎为例，来说明锁的一些特点。

锁的类型：

InnoDB存储引擎实现了如下两种标准的行级锁：

- **共享锁(S Lock)**，允许事务读一行数据
- **排他锁(X Lock)**，允许事务删除或更新一行数据

如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r的共享锁，因为读取并没有改变行r的数据，称这种情况为锁兼容。但若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁，这种情况称为锁不兼容。下图显示了共享锁和排他锁的兼容性，可以发现X锁与任何的锁都不兼容，而S锁仅和S锁兼容。需要特别注意的是，S和X锁都是行锁，兼容是指对同一记录（row）锁的兼容性情况。

![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789973420/451F7F8F13ABFA93EB8C61E59AA9C16B)

锁的粒度：

InnoDB存储引擎支持多粒度锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在。为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为意向锁。意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度上进行加锁。

InnoDB存储引擎支持意向锁设计比较简练，其意向锁即为表级别的锁。设计目的主要是为了在一个事务中揭示下一行将被请求的锁类型。其支持两种意向锁：

- 意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁。
- 意向排他锁（IX Lock），事务想要获得一张表中某几行的排他锁。

由于InnoDB存储引擎支持的是行级别的锁，因此意向锁其实不会阻塞除全表扫以外的任何请求。故表级意向锁与行级锁的兼容性如下图所示。

![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789985591/5B9177E05C401C608BFE7411DF556D06)

锁的算法：

InnoDB存储引擎有3种行锁的算法，其分别是：

- Record Lock：单个行记录上的锁。
- Gap Lock：间隙锁，锁定一个范围，但不包含记录本身。
- Next-Key Lock∶Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身。

Record Lock总是会去锁住索引记录，如果InnoDB存储引擎表在建立的时候没有设置任何一个索引，那么这时InnoDB存储引擎会使用隐式的主键来进行锁定。Next-Key Lock是结合了Gap Lock和Record Lock的一种锁定算法，在Next-Key Lock算法下，InnoDB对于行的查询都是采用这种锁定算法。采用Next-Key Lock的锁定技术称为Next-Key Locking，其设计的目的是为了解决Phantom Problem（幻读）。而利用这种锁定技术，锁定的不是单个值，而是一个范围，是谓词锁（predict lock）的一种改进。

关于死锁：

死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。若无外力作用，事务都将无法推进下去。

解决死锁问题最简单的一种方法是超时，即当两个事务互相等待时，当一个等待时间超过设置的某一阈值时，其中一个事务进行回滚，另一个等待的事务就能继续进行。

除了超时机制，当前数据库还都普遍采用wait-for graph（等待图）的方式来进行死锁检测。较之超时的解决方案，这是一种更为主动的死锁检测方式。InnoDB存储引擎也采用的这种方式。wait-for graph要求数据库保存以下两种信息：

- 锁的信息链表；
- 事务等待链表；

通过上述链表可以构造出一张图，而在这个图中若存在回路，就代表存在死锁，因此资源间相互发生等待。这是一种较为主动的死锁检测机制，在每个事务请求锁并发生等待时都会判断是否存在回路，若存在则有死锁，通常来说InnoDB存储引擎选择回滚undo量最小的事务。

锁的升级：

锁升级（Lock Escalation）是指将当前锁的粒度降低。举例来说，数据库可以把一个表的1000个行锁升级为一个页锁，或者将页锁升级为表锁。

InnoDB存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁的，相反，其根据每个事务访问的每个页对锁进行管理的，采用的是位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。

## 3.2 介绍一下间隙锁

InnoDB存储引擎有3种行锁的算法，间隙锁（Gap Lock）是其中之一。间隙锁用于锁定一个范围，但不包含记录本身。它的作用是为阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生

## 3.3 InnoDB中行级锁是怎么实现的？

InnoDB行级锁是通过给索引上的索引项加锁来实现的。只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁

当表中锁定其中的某几行时，不同的事务可以使用不同的索引锁定不同的行。另外，不论使用主键索引、唯一索引还是普通索引，InnoDB都会使用行锁来对数据加锁

## 3.4 数据库在什么情况下会发生死锁？

**死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象**。若无外力作用，事务都将无法推进下去。下图演示了死锁的一种经典的情况，即A等待B、B等待A，这种死锁问题被称为AB-BA死锁

![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645790002918/44D7A2789DD3160FFECE858FFE22923A)

## 3.5 数据库死锁的解决办法

解决死锁问题最简单的一种方法是超时，即当两个事务互相等待时，当一个等待时间超过设置的某一阈值时，其中一个事务进行回滚，另一个等待的事务就能继续进行

除了超时机制，当前数据库还都普遍采用wait-for graph（等待图）的方式来进行死锁检测。较之超时的解决方案，这是一种更为主动的死锁检测方式。InnoDB存储引擎也采用的这种方式。wait-for graph要求数据库保存以下两种信息

- **锁的信息链表**
- **事务等待链表**

通过上述链表可以构造出一张图，而在这个图中若存在回路，就代表存在死锁，因此资源间相互发生等待。这是一种较为主动的死锁检测机制，在每个事务请求锁并发生等待时都会判断是否存在回路，若存在则有死锁，通常来说InnoDB存储引擎选择回滚undo量最小的事务

## 3.6 说下对数据库优化的理解

- MySQL数据库优化是多方面的，原则是减少系统的瓶颈，减少资源的占用，增加系统的反应速度。例如，通过优化文件系统，提高磁盘I\O的读写速度；通过优化操作系统调度策略，提高MySQL在高负荷情况下的负载能力；优化表结构、索引、查询语句等使查询响应更快
- 针对**查询**，我们可以通过使用索引、使用连接代替子查询的方式来提高查询速度
- 针对**慢查询**，我们可以通过分析慢查询日志，来发现引起慢查询的原因，从而有针对性的进行优化
- 针对**插入**，我们可以通过禁用索引、禁用检查等方式来提高插入速度，在插入之后再启用索引和检查
- 针对**数据库结构**，我们可以通过将字段很多的表拆分成多张表、增加中间表、增加冗余字段等方式进行优化

## 3.7 如何优化MySQL的查询？

### 3.7.1 使用索引

如果查询时没有使用索引，查询语句将扫描表中的所有记录。在数据量大的情况下，这样查询的速度会很慢。如果使用索引进行查询，查询语句可以根据索引快速定位到待查询记录，从而减少查询的记录数，达到提高查询速度的目的。

索引可以提高查询的速度，但并不是使用带有索引的字段查询时索引都会起作用。有几种特殊情况，在这些情况下有可能使用带有索引的字段查询时索引并没有起作用。

- 使用LIKE关键字的查询语句

在使用LIKE关键字进行查询的查询语句中，如果匹配字符串的第一个字符为“%”，索引不会起作用。只有“%”不在第一个位置，索引才会起作用。

- 使用多列索引的查询语句

MySQL可以为多个字段创建索引。一个索引可以包括16个字段。对于多列索引，只有查询条件中使用了这些字段中的第1个字段时索引才会被使用。

- 使用OR关键字的查询语句

查询语句的查询条件中只有OR关键字，且OR前后的两个条件中的列都是索引时，查询中才使用索引。否则，查询将不使用索引。

### 3.7.2 优化子查询

- 使用子查询可以进行SELECT语句的嵌套查询，即一个SELECT查询的结果作为另一个SELECT语句的条件。子查询可以一次性完成很多逻辑上需要多个步骤才能完成的SQL操作
- 子查询虽然可以使查询语句很灵活，但执行效率不高。执行子查询时，MySQL需要为内层查询语句的查询结果建立一个临时表。然后外层查询语句从临时表中查询记录。查询完毕后，再撤销这些临时表。因此，子查询的速度会受到一定的影响。如果查询的数据量比较大，这种影响就会随之增大
- 在MySQL中，可以使用连接（JOIN）查询来替代子查询。连接查询不需要建立临时表，其速度比子查询要快，如果查询中使用索引，性能会更好

## 3.8 怎样插入数据才能更高效？

影响插入速度的主要是索引、唯一性校验、一次插入记录条数等。针对这些情况，可以分别进行优化

1. **对于MyISAM引擎的表，常见的优化方法如下**

- **禁用索引**

对于非空表，插入记录时，MySQL会根据表的索引对插入的记录建立索引。如果插入大量数据，建立索引会降低插入记录的速度。为了解决这种情况，可以在插入记录之前禁用索引，数据插入完毕后再开启索引。对于空表批量导入数据，则不需要进行此操作，因为MyISAM引擎的表是在导入数据之后才建立索引的

- **禁用唯一性检查**

**插入数据时，MySQL会对插入的记录进行唯一性校验**。这种唯一性校验会降低插入记录的速度。为降低这种情况对查询速度的影响，可以**在插入记录之前禁用唯一性检查，等到记录插入完毕后再开启**

- **使用批量插入**

插入多条记录时，可以使用一条INSERT语句插入一条记录，也可以使用一条INSERT语句插入多条记录。使用一条INSERT语句插入多条记录的情形如下，而这种方式的插入速度更快

```
INSERT INTO fruits VALUES ('x1', '101', 'mongo2', '5.7'), ('x2', '101', 'mongo3', '5.7'), ('x3', '101', 'mongo4', '5.7');
```

- **使用LOAD DATA INFILE批量导入**

当需要批量导入数据时，如果能用LOAD DATA INFILE语句，就尽量使用。因为LOAD DATA INFILE语句导入数据的速度比INSERT语句快

2. **对于InnoDB引擎的表，常见的优化方法如下**

- **禁用唯一性检查**

插入数据之前执行set unique_checks=0来禁止对唯一索引的检查，数据导入完成之后再运行set unique_checks=1。这个和MyISAM引擎的使用方法一样

- **禁用外键检查**

插入数据之前执行禁止对外键的检查，数据插入完成之后再恢复对外键的检查

- **禁用自动提交**

插入数据之前禁止事务的自动提交，数据导入完成之后，执行恢复自动提交操作

## 3.9 表中包含几千万条数据该怎么办？

建议按照如下顺序进行优化：

1. **优化SQL和索引**
2. **增加缓存**，如memcached、redis
3. **读写分离**，可以采用主从复制，也可以采用主主复制
4. 使用MySQL自带的分区表，这对应用是透明的，无需改代码，但SQL语句是要针对分区表做优化的
5. **做垂直拆分**，即根据模块的耦合度，将一个大的系统分为多个小的系统
6. **做水平拆分**，要选择一个合理的sharding key，为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表

## 3.10 MySQL的慢查询优化有了解吗？

优化MySQL的慢查询，可以按照如下步骤进行：

1. **开启慢查询日志**

MySQL中慢查询日志默认是关闭的，可以通过配置文件my.ini或者my.cnf中的log-slow-queries选项打开，也可以在MySQL服务启动的时候使用--log-slow-queries[=file_name]启动慢查询日志

启动慢查询日志时，需要在my.ini或者my.cnf文件中配置long_query_time选项指定记录阈值，如果某条查询语句的查询时间超过了这个值，这个查询过程将被记录到慢查询日志文件中

2. **分析慢查询日志**

直接分析mysql慢查询日志，利用explain关键字可以模拟优化器执行SQL查询语句，来分析sql慢查询语句

3. **常见慢查询优化**

**索引没起作用的情况**

- 在使用LIKE关键字进行查询的查询语句中，如果匹配字符串的第一个字符为“%”，索引不会起作用。只有“%”不在第一个位置，索引才会起作用
- MySQL可以为多个字段创建索引。一个索引可以包括16个字段。对于多列索引，只有查询条件中使用了这些字段中的第1个字段时索引才会被使用
- 查询语句的查询条件中只有OR关键字，且OR前后的两个条件中的列都是索引时，查询中才使用索引。否则，查询将不使用索引。

**优化数据库结构**

- 对于字段比较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。
- 对于需要经常联合查询的表，可以建立中间表以提高查询效率。通过建立中间表，把需要经常联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询，以此来提高查询效率。

**分解关联查询**

- 很多高性能的应用都会对关联查询进行分解，就是可以对每一个表进行一次单表查询，然后将查询结果在应用程序中进行关联，很多场景下这样会更高效

**优化LIMIT分页**

- 当偏移量非常大的时候，例如可能是limit 10000,20这样的查询，这是mysql需要查询10020条然后只返回最后20条，前面的10000条记录都将被舍弃，这样的代价很高。优化此类查询的一个最简单的方法是尽可能的使用索引覆盖扫描，而不是查询所有的列。然后根据需要做一次关联操作再返回所需的列。对于偏移量很大的时候这样做的效率会得到很大提升

## 3.11 对explain的了解

MySQL中提供了EXPLAIN语句和DESCRIBE语句，用来分析查询语句，EXPLAIN语句的基本语法如下：

```
EXPLAIN [EXTENDED] SELECT select_options
```

使用EXTENED关键字，EXPLAIN语句将产生附加信息。执行该语句，可以分析EXPLAIN后面SELECT语句的执行情况，并且能够分析出所查询表的一些特征。下面对查询结果进行解释：

- id：SELECT识别符。这是SELECT的查询序列号
- select_type：表示SELECT语句的类型
- table：表示查询的表
- type：表示表的连接类型
- possible_keys：给出了MySQL在搜索数据记录时可选用的各个索引
- key：是MySQL实际选用的索引
- key_len：给出索引按字节计算的长度，key_len数值越小，表示越快。
- ref：给出了关联关系中另一个数据表里的数据列名
- rows：是MySQL在执行这个查询时预计会从这个数据表里读出的数据行的个数
- Extra：提供了与关联操作有关的信息

DESCRIBE语句的使用方法与EXPLAIN语句是一样的，分析结果也是一样的，并且可以缩写成DESC。DESCRIBE语句的语法形式如下：

```
DESCRIBE SELECT select_options
```

## 3.12 explain关注什么？

重点要关注如下几列：

| 列名    | 备注                                                         |
| ------- | ------------------------------------------------------------ |
| type    | 本次查询表联接类型，从这里可以看到本次查询大概的效率         |
| key     | 最终选择的索引，如果没有索引的话，本次查询效率通常很差       |
| key_len | 本次查询用于结果过滤的索引实际长度                           |
| rows    | 预计需要扫描的记录数，预计需要扫描的记录数越小越好           |
| Extra   | 额外附加信息，主要确认是否出现 Using filesort、Using temporary 这两种情况 |

其中，type包含以下几种结果，从上之下依次是最差到最好：

| 类型            | 备注                                                         |
| --------------- | ------------------------------------------------------------ |
| ALL             | 执行full table scan，这是最差的一种方式。                    |
| index           | 执行full index scan，并且可以通过索引完成结果扫描并且直接从索引中取的想要的结果数据，也就是可以避免回表，比ALL略好，因为索引文件通常比全部数据要来的小。 |
| range           | 利用索引进行范围查询，比index略好。                          |
| index_subquery  | 子查询中可以用到索引。                                       |
| unique_subquery | 子查询中可以用到唯一索引，效率比 index_subquery 更高些。     |
| index_merge     | 可以利用index merge特性用到多个索引，提高查询效率。          |
| ref_or_null     | 表连接类型是ref，但进行扫描的索引列中可能包含NULL值。        |
| fulltext        | 全文检索。                                                   |
| ref             | 基于索引的等值查询，或者表间等值连接。                       |
| eq_ref          | 表连接时基于主键或非NULL的唯一索引完成扫描，比ref略好。      |
| const           | 基于主键或唯一索引唯一值查询，最多返回一条结果，比eq_ref略好。 |
| system          | 查询对象表只有一行数据，这是最好的情况。                     |

另外，Extra列需要注意以下的几种情况：

| 关键字                       | 备注                                                         |
| ---------------------------- | ------------------------------------------------------------ |
| Using filesort               | 将用外部排序而不是按照索引顺序排列结果，数据较少时从内存排序，否则需要在磁盘完成排序，代价非常高，需要添加合适的索引。 |
| Using temporary              | 需要创建一个临时表来存储结果，这通常发生在对没有索引的列进行GROUP BY时，或者ORDER BY里的列不都在索引里，需要添加合适的索引。 |
| Using index                  | 表示MySQL使用覆盖索引避免全表扫描，不需要再到表中进行二次查找数据，这是比较好的结果之一。注意不要和type中的index类型混淆。 |
| Using where                  | 通常是进行了全表/全索引扫描后再用WHERE子句完成结果过滤，需要添加合适的索引。 |
| Impossible WHERE             | 对Where子句判断的结果总是false而不能选择任何数据，例如where 1=0，无需过多关注。 |
| Select tables optimized away | 使用某些聚合函数来访问存在索引的某个字段时，优化器会通过索引直接一次定位到所需要的数据行完成整个查询，例如MIN()\MAX()，这种也是比较好的结果之一。 |

## 3.13 介绍下数据库设计的三大范式

目前关系数据库有六种范式，一般来说，**数据库只需满足第三范式(3NF）就行**

1. **第一范式（1NF）**

- 是指在关系模型中，对于添加的一个规范要求，所有的域都应该是原子性的，即数据库表的每一列都是不可分割的原子数据项，而不能是集合，数组，记录等非原子数据项
- 即实体中的某个属性有多个值时，必须拆分为不同的属性。在符合第一范式表中的每个域值只能是实体的一个属性或一个属性的一部分。简而言之，第一范式就是无重复的域

2. **第二范式（2NF）**

- 在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖）
- 第二范式是在第一范式的基础上建立起来的，即满足第二范式必须先满足第一范式。第二范式要求数据库表中的每个实例或记录必须可以被唯一地区分。选取一个能区分每个实体的属性或属性组，作为实体的唯一标识
- 例如在员工表中的身份证号码即可实现每个一员工的区分，该身份证号码即为候选键，任何一个候选键都可以被选作主键。在找不到候选键时，可额外增加属性以实现区分，如果在员工关系中，没有对其身份证号进行存储，而姓名可能会在数据库运行的某个时间重复，无法区分出实体时，设计辟如ID等不重复的编号以实现区分，被添加的编号或ID选作主键

3. **第三范式（3NF）**

- 在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖）
- 第三范式是第二范式的一个子集，即满足第三范式必须满足第二范式。简而言之，第三范式要求一个关系中不包含已在其它关系已包含的非主关键字信息
- 例如，存在一个部门信息表，其中每个部门有部门编号（dept_id）、部门名称、部门简介等信息。那么在员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果不存在部门信息表，则根据第三范式（3NF）也应该构建它，否则就会有大量的数据冗余

## 3.14 对MySQL引擎的了解

MySQL提供了多个不同的存储引擎，包括处理事务安全表的引擎和处理非事务安全表的引擎。在MySQL中，不需要在整个服务器中使用同一种存储引擎，针对具体的要求，可以对每一个表使用不同的存储引擎。MySQL 8.0支持的存储引擎有InnoDB、MyISAM、Memory、Merge、Archive、Federated、CSV、BLACKHOLE等。其中，最常用的引擎是InnoDB和MyISAM。

InnoDB存储引擎：

InnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键。MySQL 5.5.5之后，InnoDB作为默认存储引擎，主要特性如下：

1. InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事务安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表与其他MySQL表的类型混合起来，甚至在同一个查询中也可以混合。
2. InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系数据库引擎所不能匹敌的。
3. InnoDB存储引擎完全与MySQL服务器整合，为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引存在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘分区）。这与MyISAM表不同，比如在MyISAM表中每个表被存在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上。
4. InnoDB支持外键完整性约束（FOREIGN KEY）。存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6B的ROWID，并以此作为主键。
5. InnoDB被用在众多需要高性能的大型数据库站点上。InnoDB不创建目录，使用InnoDB时，MySQL将在数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件。

MyISAM存储引擎：

MyISAM基于ISAM存储引擎，并对其进行扩展。它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。MyISAM拥有较高的插入、查询速度，但不支持事务。MyISAM的主要特性如下：

1. 在支持大文件（达63位文件长度）的文件系统和操作系统上被支持。
2. 当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块以及若下一个块被删除则扩展到下一块来自动完成。
3. 每个MyISAM表最大的索引数是64，这可以通过重新编译来改变。每个索引最大的列数是16个。
4. 最大的键长度是1000B，这也可以通过编译来改变。对于键长度超过250B的情况，一个超过1024B的键将被用上。
5. BLOB和TEXT列可以被索引。
6. NULL值被允许在索引的列中，这个值占每个键的0~1个字节。
7. 所有数字键值以高字节优先被存储，以允许一个更高的索引压缩。
8. 每个表一个AUTO_INCREMENT列的内部处理。MyISAM为INSERT和UPDATE操作自动更新这一列，这使得AUTO_INCREMENT列更快（至少10%）。在序列顶的值被删除之后就不能再利用。
9. 可以把数据文件和索引文件放在不同目录。
10. 每个字符列可以有不同的字符集。
11. 有VARCHAR的表可以固定或动态记录长度。
12. VARCHAR和CHAR列可以多达64KB。

## 3.15 对redo log、undo log、binlog了解

- **binlog(Binary Log)**

  二进制日志文件就是常说的binlog。二进制日志记录了MySQL所有修改数据库的操作，然后以二进制的形式记录在日志文件中，其中还包括每条语句所执行的时间和所消耗的资源，以及相关的事务信息

  默认情况下，二进制日志功能是开启的，启动时可以重新配置--log-bin[=file_name]选项，修改二进制日志存放的目录和文件名称

- **redo log**

  重做日志用来实现事务的持久性，即事务ACID中的D。它由两部分组成：一是内存中的重做日志缓冲(redo log buffer)，其是易失的；二是重做日志文件（redo log file），它是持久的

  InnoDB是事务的存储引擎，它通过Force Log at Commit机制实现事务的持久性，即当事务提交（COMMIT）时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的COMMIT操作完成才算完成。这里的日志是指重做日志，在InnoDB存储引擎中，由两部分组成，即redo log和undo log

  redo log用来保证事务的持久性，undo log用来帮助事务回滚及MVCC的功能。redo log基本上都是顺序写的，在数据库运行时不需要对redo log的文件进行读取操作。而undo log是需要进行随机读写的

- **undo log**

  重做日志记录了事务的行为，可以很好地通过其对页进行“重做”操作。但是事务有时还需要进行回滚操作，这时就需要undo。因此在对数据库进行修改时，InnoDB存储引擎不但会产生redo，还会产生一定量的undo。这样如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条ROLLBACK语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子

  redo存放在重做日志文件中，与redo不同，undo存放在数据库内部的一个特殊段(segment)中，这个段称为undo段(undo segment)，undo段位于共享表空间内

## 3.16 对MVCC的了解

InnoDB默认的隔离级别是RR（REPEATABLE READ），RR解决脏读、不可重复读、幻读等问题，使用的是MVCC。MVCC全称Multi-Version Concurrency Control，即多版本的并发控制协议。它最大的优点是读不加锁，因此读写不冲突，并发性能好。InnoDB实现MVCC，多个版本的数据可以共存，主要基于以下技术及数据结构：

1. 隐藏列：InnoDB中每行数据都有隐藏列，隐藏列中包含了本行数据的事务id、指向undo log的指针等。
2. 基于undo log的版本链：每行数据的隐藏列中包含了指向undo log的指针，而每条undo log也会指向更早版本的undo log，从而形成一条版本链。
3. ReadView：通过隐藏列和版本链，MySQL可以将数据恢复到指定版本。但是具体要恢复到哪个版本，则需要根据ReadView来确定。所谓ReadView，是指事务（记做事务A）在某一时刻给整个事务系统（trx_sys）打快照，之后再进行读操作时，会将读取到的数据中的事务id与trx_sys快照比较，从而判断数据对该ReadView是否可见，即对事务A是否可见。

## 3.17 MySQL主从同步是如何实现的？

**复制(replication)是MySQL数据库提供的一种高可用高性能的解决方案，一般用来建立大型的应用**。总体来说，replication的工作原理分为以下3个步骤：

1. **主服务器(master)把数据更改记录到二进制日志(binlog)中**
2. **从服务器(slave)把主服务器的二进制日志复制到自己的中继日志(relay log)中**
3. **从服务器重做中继日志中的日志，把更改应用到自己的数据库上，以达到数据的最终一致性**

复制的工作原理并不复杂，其实就是一个完全备份加上二进制日志备份的还原。不同的是这个二进制日志的还原操作基本上实时在进行中。这里特别需要注意的是，复制不是完全实时地进行同步，而是异步实时。这中间存在主从服务器之间的执行延时，如果主服务器的压力很大，则可能导致主从服务器延时较大。复制的工作原理如下图所示，其中从服务器有2个线程，一个是I/O线程，负责读取主服务器的二进制日志，并将其保存为中继日志；另一个是SQL线程，复制执行中继日志

# 4 C++八股

## 4.1 一二三范式  

1) **第⼀范式**：数据库表中的字段都是单⼀属性的，不可再分。每⼀个属性都是原⼦项，不可分割。如果实体中的某个属性有多个值时，必须拆分为不同的属性通俗解释。 1NF是关系模式应具备的最起码的条件，如果数据库设计不能满⾜第⼀范式，就不称为**关系型数据库**。也就是说，**只要是关系型数据库，就⼀定满足第一范式**

2) **第⼆范式**：数据库表中不存在⾮关键字段对任⼀候选关键字段的部分函数依赖，即符合第⼆范式。如果⼀个表中某⼀个字段A的值是由另外⼀个字段或⼀组字段B的值来确定的，就称为A函数依赖于B。当某张表中的非主键信息不是由整个主键函数来决定时，即存在依赖于该表中不是主键的部分或者依赖于主键⼀部分的部分时，通常会违反2NF

3) **第三范式**：在第⼆范式的基础上，数据表中如果不存在非关键字段对任⼀候选关键字段的传递函数依赖则符合3NF。第三范式规则查找以消除没有直接依赖于第⼀范式和第⼆范式形成的表的主键的属性。我们为没有与表的主键关联的所有信息建⽴了⼀张新表。每张新表保存了来自源表的信息和它们所依赖的主键；如果某⼀属性依赖于其他⾮主键属性，而其他非主键属性⼜依赖于主键，那么这个属性就是间接依赖于主键，这被称作传递依赖于主属
   性。 通俗理解：⼀张表最多只存2层同类型信息

## 4.2 数据库的索引类型，数据库索引的作用

1) **数据库索引好⽐是⼀本书前⾯的⽬录，能加快数据库的查询速度**。索引是对数据库表中⼀个或多个列(例如，employee 表的姓⽒ (lname) 列)的值进⾏排序的结构。如果想按特定职员的姓来查找他或她，则与在表中搜索所有的⾏相⽐，索引有助于更快地获取信息

2) **优点**

   ⼤⼤加快数据的检索速度，创建唯⼀性索引，保证数据库表中每⼀⾏数据的唯⼀性。加速表和表之间的连接，在使⽤分组和排序⼦句进⾏数据检索时，可以显著减少查询中分组和排序的时间

3) **缺点**

   索引需要占用数据表以外的物理存储空间，创建索引和维护索引要花费⼀定的时间，当对表进行更新操作时，索引要被重建，这样降低数据的维护速度

4) 类型

- **唯⼀索引UNIQUE**：例如create unique index stusno on student(sno)，表明此索引的每⼀个索引值只对应唯⼀的数据记录，对于单列惟⼀性索引，这保证单列不包含重复的值。对于多列惟⼀性索引，保证多个值的组合不重复
- **主键索引primary key**：数据库表经常有⼀列或列组合，其值唯⼀标识表中的每⼀⾏。该列称为表的主键。 在数据库关系图中为表定义主键将⾃动创建主键索引，主键索引是唯⼀索引的特定类型。该索引要求主键中的每个值都唯⼀。当在查询中使⽤主键索引时，它还允许对数据的快速访问
- **聚集索引(也叫聚簇索引)cluster**：在聚集索引中，表中⾏的物理顺序与键值的逻辑（索引）顺序相同。⼀个表只能包含⼀个聚集索引，如果某索引不是聚集索引，则表中⾏的物理顺序与键值的逻辑顺序不匹配。与⾮聚集索引相⽐，聚集索引通常提供更快的数据访问速度

5) **实现方式**

   B+树、散列索引、位图索引

## 4.3 聚集索引和非聚集索引的区别

1) 聚集索引表示**表中存储的数据按照索引的顺序存储，检索效率比非聚集索引高，但对数据更新影响较大**。⾮聚集索引表示数据存储在⼀个地⽅，索引存储在另⼀个地⽅，索引带有指针指向数据的存储位置，⾮聚集索引检索效率⽐聚集索引低，但对数据更新影响较⼩

2) **聚集索引一个表只能有⼀个，非聚集索引一个表可以存在多个**。聚集索引存储记录是物理上连续存在，⽽⾮聚集索引是逻辑上的连续，物理存储并不连续

## 4.4 唯一性索引和主键索引的区别

对于主健索引， oracle/sql server/mysql 等都会⾃动建⽴唯⼀索引：

- 主键不⼀定只包含⼀个字段，所以如果在主键的其中⼀个字段建唯⼀索引还是必要的
- 主健可作外健，唯⼀索引不可
- 主健不可为空，唯⼀索引可以
- 主健也可是多个字段的组合
- 主键与唯⼀索引不同的是
- 主键索引有 not null 属性
- 主键索引每个表只能有⼀个

## 4.5 数据库引擎，innodb和myisam的特点与区别

1) Innodb引擎提供对数据库ACID事务的⽀持，并且实现SQL标准的四种隔离级别，关于数据库事务与其隔离级别的内容请⻅数据库事务与其隔离级别这篇⽂章。该引擎还提供⾏级锁和外键约束，它的设计⽬标是处理⼤容量数据库系统，它本身其实就是**基于MySQL后台的完整数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引**。但该引擎不⽀持FULLTEXT类型的索引，⽽且它没有保存表的⾏数，当SELECT COUNT(*) FROM TABLE时需要扫描全表。当需要使⽤数据库事务时，该引擎当然是⾸选。由于锁的粒度更⼩，写操作不会锁定全表，所以在并发较⾼时，使⽤Innodb引擎会提升效率。但是使⽤⾏级锁也不是绝对的，如果在执⾏⼀个SQL语句时MySQL不能确定要扫描的范围， InnoDB表同样会锁全表

2) MyIASM是MySQL默认的引擎，但是它没有提供对数据库事务的⽀持，也不⽀持⾏级锁和外键，因此当INSERT(插⼊)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低⼀些。不过和Innodb不同， MyIASM中存储表的⾏数，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值⽽不需要进⾏全表扫描。如果表的读操作远远多于写操作且不需要数据库事务的⽀持，那么MyIASM也是很好的选择

3) ⼤尺⼨的数据集趋向于选择InnoDB引擎，因为它⽀持事务处理和故障恢复。数据库的⼤⼩决定故障恢复的时间⻓短， InnoDB可以利⽤事务⽇志进⾏数据恢复，这会⽐较快。主键查询在InnoDB引擎下也会相当快，不过需要
   注意的是如果主键太⻓也会导致性能问题，关于这个问题我会在下⽂中讲到。⼤批的INSERT语句(在每个INSERT语句中写⼊多⾏，批量插⼊)在MyISAM下会快⼀些，但是UPDATE语句在InnoDB下则会更快⼀些，尤其是在并发量⼤的时候

## 4.6 关系型和非关系型数据库的区别

![关系型和非关系型数据库](E:\BaiduSyncdisk\C++学习\B站C++学习\1.C++学习\2.数据库\C++八股笔记图片\关系型和非关系型数据库.png)

## 4.7 数据库的隔离级别

- **隔离级别⾼的数据库的可靠性高，但并发量低，而隔离级别低的数据库可靠性低，但并发量高，系统开销小**

1) **READ UNCIMMITTED(未提交读)**：事务中的修改，即使没有提交，其他事务也可以看得到，⽐如说上⾯的两步这种现象就叫做脏读，这种隔离级别会引起很多问题，如⽆必要，不要随便使⽤；这就是事务还没提交，⽽别的事务可以看到他其中修改的数据的后果，也就是脏读；

3) **READ COMMITTED(提交读)**：⼤多数数据库系统的默认隔离级别是READ COMMITTED，这种隔离级别就是⼀个事务的开始，只能看到已经完成的事务的结果，正在执⾏的，是⽆法被其他事务看到的。这种级别会出现读取旧数据的现象

4) **REPEATABLE READ(可重复读)**：**REPEATABLE READ解决脏读的问题**，该级别保证每⾏的记录的结果是⼀致的，也就是上⾯说的读旧数据的问题，但是却⽆法解决另⼀个问题，幻⾏，顾名思义就是突然蹦出来的⾏数据。指的就是某个事务在读取某个范围的数据，但是另⼀个事务⼜向这个范围的数据去插⼊数据，导致多次读取的时候，数据的⾏数不⼀致。虽然读取同⼀条数据可以保证⼀致性，但是却不能保证没有插⼊新的数据

5) **SERIALIZABLE(可串行化)**：SERIALIZABLE是最⾼的隔离级别，它通过强制事务串行执行(注意是串行)，避免前⾯的幻读情况，由于他⼤量加上锁，导致⼤量的请求超时，因此性能会比较底下，再特别需要数据⼀致性且并发量不需要那么⼤的时候才可能考虑这个隔离级别

## 4.8 数据库连接池的作用

1) 在内部对象池中，维护⼀定数量的数据库连接，并对外暴露数据库连接的获取和返回⽅法，如外部使⽤者可通过getConnection⽅法获取数据库连接，使⽤完毕后再通过releaseConnection⽅法将连接返回，注意此时的连接并
   没有关闭，⽽是由连接池管理器回收，并为下⼀次使⽤做好准备

2) 资源重⽤，由于数据库连接得到重⽤，避免了频繁创建、释放连接引起的⼤量性能开销。在减少系统消耗的基础上，增进系统环境的平稳性(减少内存碎⽚以级数据库临时进程、线程的数量)

3) 更快的系统响应速度，数据库连接池在初始化过程中，往往已经创建若⼲数据库连接置于池内备⽤。此时连接池的初始化操作均已完成。对于业务请求处理⽽⾔，直接利⽤现有可⽤连接，避免数据库连接初始化和释放过程的时间开销，从⽽缩减系统整体响应时间

4) 新的资源分配⼿段，对于多应⽤共享同⼀数据库的系统⽽⾔，可在应⽤层通过数据库连接的配置，实现数据库连接技术

5) 统⼀的连接管理，避免数据库连接泄露，较较为完备的数据库连接池实现中，可根据预先的连接占⽤超时设定，强制收回被占⽤的连接，从⽽避免常规数据库连接操作中可能出现的资源泄露

## 4.9 数据的锁的种类，加锁的方式

1) 锁是⽹络数据库中的⼀个⾮常重要的概念，**当多个用户同时对数据库并发操作时，会带来数据不⼀致的问题，所以锁主要用于多用户环境下保证数据库完整性和一致性**

2) 数据库锁出现的目的：处理并发问题
3) 并发控制的主要采用的技术手段：**乐观锁、悲观锁和时间戳**
4) 从数据库系统⻆度分为三种：**排他锁、共享锁、更新锁**。从程序员⻆度分为两种：**一种是悲观锁，一种乐观锁**

## 4.10 数据库union join的区别

1) join 是两张表做交连后⾥⾯条件相同的部分记录产⽣⼀个记录集， union是产⽣的两个记录集(字段要⼀样的)并在⼀起，成为⼀个新的记录集

2) union在数据库运算中会过滤掉重复数据，并且合并之后的是根据⾏合并的，即：如果a表和b表中的数据各有五行，且有两行是重复数据，合并之后为8⾏。运⽤场景：适合于需要进⾏统计的运算

3) union all是进⾏全部合并运算的，即：如果a表和b表中的数据各有五⾏，且有两⾏是重复数据，合并之后为10⾏

4) join是进行表关联运算的，两个表要有⼀定的关系。即：如果a表和b表中的数据各有五行，且有两⾏是重复数据，根据某⼀列值进⾏笛卡尔运算和条件过滤，假如a表有2列， b表有2列， join之后是4列

## 4.11 面试前必知MySQL常用命令

- **启动与退出**

**指定 IP 地址和端口号登录 MySQL 数据库**

命令格式为：

```
mysql -h ip -u root -p -P 3306
```

例如：

```
mysql -h 127.0.0.1 -u root -p -P 3306
```

- **退出 MySQL**

使⽤ quit 或 exit 退出 MySQL

- **查看数据库**

```
SHOW DATABASES;
```

- **创建数据库**

```
CREATE DATABASE IF NOT EXISTS dbname;
```

- **选择数据库**

```
USE 数据库名 ;
```

- **查看数据库中的数据表**

```
SHOW TABLES ;
```

- **删除数据库**

```
DROP DATABASE IF EXISTS dbname;
```

- **创建⼀个简单的数据库表**

```
字段 类型(⻓度) 属性 索引
```

```
CREATE TABLE IF NOT EXISTS 表名(
id INT UNSTGND AUTO_INCREMENT PRIMARY KEY,
name VARCHAR(255) NOT NULL
)ENGINE = InnoDB DEFAULT CHARSET=utf8;
```

- **添加数据**

```
INSERT INTO table_name ( field1, field2,...fieldN )VALUES ( value1, value2,...valueN );
```

- **查询数据**

```
SELECT * FROM table;
```

- **修改数据**

```
UPDATE table SET 字段1 = '值1', 字段1='值2' WHERE 条件 ;
```

- **删除数据**

```
DELETE FROM table WHERE 条件 ;
```

- **创建新普通用户**

```
GRANT 权限 ON 库名.表名 TO '⽤户名'@'主机名' IDENTIFIED BY '密码'
```

- **查询所有用户**

```
SELECT user,host FROM mysql.user;
```

- **删除普通用户**

```
DROP USER '⽤户名'@'主机名';
```

- **修改 root 用户密码**

```
SET PASSWORD = PASSWORD('新密码');
```

- **root 用户修改普通用户密码**

```
SET PASSWORD FOR '⽤户名'@'主机名'=PASSWORD('新密码');
```

- **授权**

```
GRANT 权限 ON 库名.表名 TO '⽤户名'@'主机名' IDENTIFIED BY '密码';
GRANT SELECT,INSERT,UPDATE,DELETE ON cendxia.user TO '⽤户名'@'主机名' IDENTIFIED BY '密码';
```

- **查看权限**

```
SHOW GRANTS FOR '⽤户名'@'主机名';
```

- **收回权限**

```
REVOKE 权限 ON 库名.表名 FROM '⽤户名'@'主机名';
```

- **备份**

```
mysqldump -u root -p 数据库名 > 要保存的位置
```

- **还原数据**

```
mysql -u yser -p dbname < filename.sql;
```

- **建表引擎**

```
MyISAM -- 读取速度快，不⽀持事务
InnoDB -- 读取速度稍慢 ⽀持事务 事务回滚
```

- **⼀些常用属性**

```
UNSTGND ⽆符号属性
AUTO_INCREMENT ⾃增属性(⼀般⽤在id字段上)
ZEROFILL 零填充
```

- **字符串类型**

```
CHAR 定⻓的字符串类型 (0-255)个字符
VARCHAR 变⻓的字符串类型， 5.0以前(0-255)个字符， 5.0版本以后(0-65535)个字符
```

- **查看表结构**

```
DESC 表名; (缩写版)
DESCRIBE 表名;
```

- **查看建表语句**

```
SHOW CREATE TABLE 表名;
```

- **修改表名**

```
ALTER TABLE 原表名 RENAME TO 新表名;
```

- **修改字段的数据类型**

```
ALTER TABLE 表名 MODIFY 字段名 数据类型 属性 索引;
ALTER TABLE testalter_tbl MODIFY c CHAR(10);
```

- **修改字段名**

```
ALTER TABLE 表名 CHANGE 原字段名 新字段名 数据类型 属性 索引;
```

- **增加字段**

```
ALTER TABLE 表名 ADD 字段名 数据类型 属性 索引;
-- [FIRST|AFIER 字段名]
-- (FIRST 在最前⾯添加字段。 AFIER 字段名 在某字段后⾯添加)
```

- **删除字段**

```
ALTER TABLE 表名 DROP 字段名;
```

- **修改字段的排列位置**

```
ALTER TABLE 表名 MODIFY 字段名 数据类型 属性 索引 AFIER 字段名;
```

- **修改表引擎**

```
ALTER TABLE 表名 ENGINE=引擎名; --MyISAM 或 InnoDB
```

- **高级用法**

```
explain sql;
```

- explain 命令我们可以学习到该条 SQL 是如何执⾏的，随后解析 explain 的结果可以帮助我们使⽤更好的索引，最终来优化它
- 通过 explain 命令我们可以知道以下信息
- 表的读取顺序，数据读取操作的类型，哪些索引可以使⽤，哪些索引实际使⽤，表之间的引用，每张表有多少行被优化器查询等信息

- **格式化输出**

```
sql \G
在命令最后⾯加上 \G 即可
```

- **查看帮助**

```
在 MySQL 提示符中输⼊ help;
或者 \h 获取使⽤帮助  
```

