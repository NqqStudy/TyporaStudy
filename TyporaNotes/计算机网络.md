# 1 C++面试宝典

## 1.1 简述静态路由和动态路由

- **静态路由是由系统管理员设计与构建的路由表规定的路由**。适用于网关数量有限的场合，且网络拓朴结构不经常变化的网络。其缺点是不能动态地适用网络状况的变化，当网络状况变化后必须由网络管理员修改路由表
- **动态路由是由路由选择协议而动态构建的，路由协议之间通过交换各自所拥有的路由信息实时更新路由表的内容**。动态路由可以自动学习网络的拓朴结构，并更新路由表。其缺点是路由广播更新信息将占据大量的网络带宽

## 1.2 有哪些路由协议，都是如何更新

**路由可分为静态&动态路由。静态路由由管理员手动维护；动态路由由路由协议自动维护**

路由选择算法的必要步骤：

- 向其它路由器传递路由信息
- 接收其它路由器的路由信息

- 根据收到的路由信息计算出到每个目的网络的最优路径，并由此生成路由选择表
- 根据网络拓扑的变化及时的做出反应，调整路由生成新的路由选择表，同时把拓扑变化以路由 信息的形式向其它路由器宣告。

两种主要算法：**距离向量法**(Distance Vector Routing)和**链路状态算法**(Link-State Routing)

由此可分为距离矢量(如：RIP、IGRP、EIGRP)&链路状态路由协议(如：OSPF、IS-IS)。 路由协议是路由器之间实现路由信息共享的一种机制，它允许路由器之间相互交换和维护各自的路由表。当一台路由器的路由表由于某种原因发生变化时，它需要及时地将这一变化通知与之相连接的其他路由器，以保证数据的正确传递。路由协议不承担网络上终端用户之间 的数据传输任务。

- **RIP 路由协议**：RIP 协议最初是为 Xerox 网络系统的 Xerox parc 通用协议而设计的，是 Internet 中常用的 路由协议。**RIP 采用距离向量算法，即路由器根据距离选择路由，所以也称为距离向量协议**。 路由器收集所有可到达目的地的不同路径，并且保存有关到达每个目的地的最少站点数的路 径信息，除到达目的地的最佳路径外，任何其它信息均予以丢弃。同时路由器也把所收集的 路由信息用 RIP 协议通知相邻的其它路由器。这样，正确的路由信息逐渐扩散到了全网。RIP 使用非常广泛，它简单、可靠，便于配置。但是 RIP 只适用于小型的同构网络，因 为它允许的最大站点数为 15，任何超过 15 个站点的目的地均被标记为不可达。而且 RIP 每 隔 30s 一次的路由信息广播也是造成网络的广播风暴的重要原因之一
- **OSPF 路由协议**：OSPF 是一种基于链路状态的路由协议，需要每个路由器向其同一管理域的所有其它路 由器发送链路状态广播信息。在 OSPF 的链路状态广播中包括所有接口信息、所有的量度和其它一些变量。利用 OSPF 的路由器首先必须收集有关的链路状态信息，并根据一定的算法 计算出到每个节点的最短路径。而基于距离向量的路由协议仅向其邻接路由器发送有关路由 更新信息。与 RIP 不同，OSPF 将一个自治域再划分为区，相应地即有两种类型的路由选择方式： 当源和目的地在同一区时，采用区内路由选择；当源和目的地在不同区时，则采用区间路由 选择。这就大大减少了网络开销，并增加了网络的稳定性。当一个区内的路由器出了故障时 并不影响自治域内其它区路由器的正常工作，这也给网络的管理、维护带来方便
- **BGP 和 BGP4 路由协议**：BGP 是为 TCP／IP 互联网设计的外部网关协议，用于多个自治域之间。它既不是基于纯 粹的链路状态算法，也不是基于纯粹的距离向量算法。它的主要功能是与其它自治域的 BGP 交换网络可达信息。各个自治域可以运行不同的内部网关协议。BGP 更新信息包括网络号／ 自治域路径的成对信息。自治域路径包括到达某个特定网络须经过的自治域串，这些更新信 息通过 TCP 传送出去，以保证传输的可靠性。为了满足 Internet 日益扩大的需要，BGP 还在不断地发展。在最新的 BGP4 中，还可以 将相似路由合并为一条路由
- **IGRP 和 EIGRP 协议**：EIGRP 和早期的 IGRP 协议都是由 Cisco 发明，是基于距离向量算法的动态路由协议。 EIGRP(Enhanced Interior Gateway Routing Protocol)是增强版的 IGRP 协议。它属于动态内部网 关路由协议，仍然使用矢量－距离算法。但它的实现比 IGRP 已经有很大改进，其收敛特性 和操作效率比 IGRP 有显著的提高。它的收敛特性是基于 DUAL ( Distributed Update Algorithm ) 算法的。DUAL 算法使得路径 在路由计算中根本不可能形成环路。它的收敛时间可以与已存在的其他任何路由协议相匹敌
- Enhanced IGRP 与其它路由选择协议之间主要区别包括：**收敛宽速**(Fast Convergence)、 **支持变长子网掩模**(Subnet Mask)、局部更新和多网络层协议。执行 Enhanced IGRP 的路由 器存储了所有其相邻路由表，以便于它能快速利用各种选择路径（Alternate Routes）。如果没有合适路径，Enhanced IGRP 查询其邻居以获取所需路径。直到找到合适路径，EnhancedIGRP 查询才会终止，否则一直持续下去
- EIGRP 不作周期性更新。当路径度量标准改变时，Enhanced IGRP 只发送局 部更新(Partial Updates)信息。局部更新信息的传输自动受到限制，从而使得只有那些需 要信息的路由器才会更新。基于以上这两种性能，因此 Enhanced IGRP 损耗的带宽比 IGRP 少得多

## 1.3 简述域名解析过程，本机如何干预域名解析

### 1.3.1 域名解析过程

- 在浏览器中输入[www.qq.com](http://www.qq.com/)域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析
- 如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析
- 如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/IP参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性
- 如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性
- 如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到[www.qq.com](http://www.qq.com/)主机
- 如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机
- 从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间就是的交互查询就是迭代查询

### 1.3.2 本机干预域名

- **通过修改本机host来干预域名解析**，例如： 在/etc/hosts文件中添加一句话

```
 192.168.188.1 www.baidu.com
```

保存文件后再ping一下www.baidu.com就会连接到192.168.188.1

每一行为一条记录，分成两部分，**第一部分是IP，第二部分是域名**

- 一个IP后面可以跟多个域名，可以是几十个甚至上百个
- 每一行只能有一个IP，也就是说一个域名不能对应多个IP
- 如果有多行中出现相同的域名（对应的ip不一样），会按最前面的记录来解析

## 1.4 简述 DNS 查询服务器的基本流程是什么？DNS 劫持是什么？

1. 打开浏览器，输入一个域名。比如输入www.163.com。这时，使用的**电脑会发出一个DNS请求到本地DNS服务器**。本地DNS服务器一般都是你的网络接入服务器商提供，比如中国电信，中国移动

   DNS请求到达本地DNS服务器之后，本地DNS服务器会首先查询它的缓存记录，如果缓存中有此条记录，就可以直接返回结果。如果没有，本地DNS服务器还要向DNS根服务器进行查询

   根DNS服务器没有记录具体的域名和IP地址的对应关系，而是告诉本地DNS服务器，你可以到域服务器上去继续查询，并给出域服务器的地址

   本地DNS服务器继续向域服务器发出请求，在这个例子中，请求的对象是.com域服务器。.com域服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是告诉本地DNS服务器，你的域名的解析服务器的地址

   最后，本地DNS服务器向域名的解析服务器发出请求，这时就能收到一个域名和IP地址对应关系，本地DNS服务器不仅要把IP地址返回给用户电脑，还要把这个对应关系保存在缓存中，以备下次别的用户查询时，可以直接返回结果，加快网络访问

2. DNS劫持就是通过劫持DNS服务器，通过某些手段取得某域名的解析记录控制权，进而修改此域名的解析结果，导致对该域名的访问由原IP地址转入到修改后的指定IP，其结果就是对特定的网址不能访问或访问的是假网址，从而实现窃取资料或者破坏原有正常服务的目的。DNS劫持通过篡改DNS服务器上的数据返回给用户一个错误的查询结果来实现的

   DNS劫持症状：在某些地区的用户在成功连接宽带后，首次打开任何页面都指向ISP提供的“电信互联星空”、“网通黄页广告”等内容页面。还有就是曾经出现过用户访问Google域名的时候出现了百度的网站。这些都属于DNS劫持

## 1.5 简述网关的作用是什么，同一网段的主机如何通信

- 网关即网络中的关卡，我们的互联网是一个一个的局域网、城域网、等连接起来的，在连接点上就是一个一个网络的关卡，即我们的网关，他是保证网络互连的，翻译和转换，使得不同的网络体系能够进行
- 网内通信，即通信双方都位处同一网段中，数据传输无需经过路由器(或三层交换机)，即可由本网段自主完成

假设发送主机的ARP表中并无目的主机对应的表项，则发送主机会以目的主机IP地址为内容，广播ARP请求以期获知目的主机MAC地址，并通过交换机(除到达端口之外的所有端口发送，即洪泛(Flooding))向全网段主机转发，而只有目的主机接收到此ARP请求后会将自己的MAC地址和IP地址装入ARP应答后将其回复给发送主机，发送主机接收到此ARP应答后，从中提取目的主机的MAC地址，并在其ARP表中建立目的主机的对应表项(IP地址到MAC地址的映射)，之后即可向目的主机发送数据，将待发送数据封装成帧，并通过二层设备(如交换机)转发至本网段内的目的主机，自此完成通信

## 1.6 简述CSRF攻击的思想以及解决方法

1. CSRF全称叫做，跨站请求伪造。就是黑客可以伪造用户的身份去做一些操作，进而满足自身目的

   要完成一次CSRF攻击，受害者必须依次完成两个步骤：

   1）登录受信任网站A，并在本地生成Cookie

   2）在不登出A的情况下，访问危险网站B

   此时，黑客就可以获取你的cookie达成不可告人的目的

2. CSRF 攻击是一种请求伪造的攻击方式，它利用的是服务器不能识别用户的类型从而盗取用户的信息来攻击。因此要防御该种攻击，因为从服务器端着手，增强服务器的识别能力，设计良好的防御机制。主要有以下几种方式：

   1）请求头中的Referer验证（不推荐）

   HTTP的头部有一个Referer信息的字段，它记录着该次HTTP请求的来源地址（即它从哪里来的）,既然CSRF攻击是伪造请求是从服务器发送过来的，那么我们就禁止跨域访问，在服务器端增加验证，过滤掉那些不是从本服务器发出的请求，这样可以在一定程度上避免CSRF攻击。 但是这也有缺点，比如如果是从搜索引擎所搜结果调整过来，请求也会被认为是跨域请求

   2）请求令牌验证（token验证）

   token验证是一种比较广泛使用的防止CSRF攻击的手段，当用户通过正常渠道访问服务器时，服务器会生成一个随机的字符串保存在session中，并作为令牌（token）返回给客户端，以隐藏的形式保存在客户端中，客户端每次请求都会带着这个token，服务器根据该token判断该请求是否合法

## 1.7 MAC地址和IP地址分别有什么作用

1. **IP地址是IP协议提供的一种统一的地址格式**，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。而MAC地址，指的是物理地址，用来定义网络设备的位置
2. IP地址的分配是**根据网络的拓扑结构**，而不是根据谁制造了网络设置。若将高效的路由选择方案建立在设备制造商的基础上而不是网络所处的拓朴位置基础上，这种方案是不可行的
3. 当存在一个附加层的地址寻址时，设备更易于移动和维修。例如，如果一个以太网卡坏了，可以被更换，而无须取得一个新的IP地址。如果一个IP主机从一个网络移到另一个网络，可以给它一个新的IP地址，而无须换一个新的网卡
4. 无论是局域网，还是广域网中的计算机之间的通信，最终都表现为将数据包从某种形式的链路上的初始节点出发，从一个节点传递到另一个节点，最终传送到目的节点。数据包在这些节点之间的移动都是由**ARP**(Address Resolution Protocol：地址解析协议)负责**将IP地址映射到MAC地址上来完成的**

## 1.8 简述TCP三次握手和四次挥手过程(重点)

### 1.8.1 三次握手

![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789276099/AB3FC1B1325FA341A39644BA061FA439)

- **第一次握手**：**建立连接时，客户端向服务器发送SYN包(seq=x)，请求建立连接，等待确认**
- **第二次握手**：**服务端收到客户端的SYN包，回一个ACK包(ACK=x+1)确认收到，同时发送一个SYN包(seq=y)给客户端**
- **第三次握手**：**客户端收到SYN+ACK包，再回一个ACK包(ACK=y+1)告诉服务端已经收到**
- **三次握手完成，成功建立连接，开始传输数据**

### 1.8.2 四次挥手

![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789288423/2F42938B52A4B6494AA9CD8FCE658EBD)

- **客户端发送FIN包(FIN=1)给服务端，告诉它自己的数据已经发送完毕，请求终止连接**，此时客户端不发送数据，但还能接收数据
- **服务端收到FIN包，回一个ACK包给客户端告诉它已经收到包，此时还没有断开socket连接**，而是等待剩下的数据传输完毕
- **服务端等待数据传输完毕后，向客户端发送FIN包，表明可断开连接**
- **客户端收到后，回一个ACK包表明确认收到，等待一段时间，确保服务端不再有数据发过来，然后彻底断开连接**

## 1.9 简述TCP2次握手行不行为什么要3次

1. 为了实现可靠数据传输， TCP 协议的通信双方， 都必须维护一个序列号， 以标识发送出去的数据包中， 哪些是已经被对方收到的。 三次握手的过程即是通信双方相互告知序列号起始值， 并确认对方已经收到了序列号起始值的必经步骤
2. 如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认

## 1.10 简述 TCP 和 UDP 的区别，它们的头部结构是什么样的(重点)

- **TCP协议是有连接的，意思是开始传输实际数据之前TCP的客户端和服务器端必须通过三次握手建立连接，会话结束之后也要结束连接。而UDP是无连接的**
- **TCP协议保证数据按序发送，按序到达，提供超时重传来保证可靠性，但是UDP不保证按序到达，甚至不保证到达，只是努力交付，即便是按序发送的序列，也不保证按序送到**
- **TCP协议所需资源多，TCP首部需20个字节(不算可选项)，UDP首部字段只需8个字节**
- **TCP有流量控制和拥塞控制，UDP没有，网络拥堵不会影响发送端的发送速率**
- **TCP是一对一的连接，而UDP则可以支持一对一，多对多，一对多的通信**
- **TCP面向的是字节流的服务，UDP面向的是报文的服务**

TCP头部结构如下：

```
/*TCP头定义，共20个字节*/ 
typedef struct _TCP_HEADER {  short m_sSourPort;       
// 源端口号16bit  
short m_sDestPort; // 目的端口号16bit  unsigned int m_uiSequNum;       // 序列号32bit  unsigned int m_uiAcknowledgeNum;  // 确认号32bit  short m_sHeaderLenAndFlag;  // 前4位：TCP头长度；中6位：保留；后6位：标志位  
short m_sWindowSize;   // 窗口大小16bit  
short m_sCheckSum;    // 检验和16bit  short m_surgentPointer;     // 紧急数据偏移量16bit }__attribute__((packed))TCP_HEADER, *PTCP_HEADER;
```

```
/* TCP头中的选项定义 kind(8bit)+Length(8bit，整个选项的长度，包含前两部分)+内容(如果有的话) KIND = 1
```

## 1.11 简述 TCP 连接和关闭的具体步骤

1. **TCP通过三次握手建立链接**

![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789308210/CCB2A0BB28BC6E81E303D2AD15DF485C)

- 第一次握手：建立连接时，客户端向服务器发送SYN包（seq=x），请求建立连接，等待确认
- 第二次握手：服务端收到客户端的SYN包，回一个ACK包（ACK=x+1）确认收到，同时发送一个SYN包（seq=y）给客户端
- 第三次握手：客户端收到SYN+ACK包，再回一个ACK包（ACK=y+1）告诉服务端已经收到
- 三次握手完成，成功建立连接，开始传输数据

2. **通过4次挥手关闭链接**

![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789324845/C56CC942C12FE78B68EF6F7DB33AC08F)

- 客户端发送FIN包（FIN=1）给服务端，告诉它自己的数据已经发送完毕，请求终止连接，此时客户端不发送数据，但还能接收数据
- 服务端收到FIN包，回一个ACK包给客户端告诉它已经收到包了，此时还没有断开socket连接，而是等待剩下的数据传输完毕
- 服务端等待数据传输完毕后，向客户端发送FIN包，表明可以断开连接
- 客户端收到后，回一个ACK包表明确认收到，等待一段时间，确保服务端不再有数据发过来，然后彻底断开连接

## 1.12 简述 TCP 连接和关闭的状态转移

状态转换如图所示：

![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789338936/2FC8F26DA99E984EF442E4AB1024E75F)

上半部分是TCP三路握手过程的状态变迁，下半部分是TCP四次挥手过程的状态变迁。

1. **CLOSED**：起始点，在超时或者连接关闭时候进入此状态，这并不是一个真正的状态，而是这个状态图的假想起点和终点
2. **LISTEN**：服务器端等待连接的状态。服务器经过 socket，bind，listen 函数之后进入此状态，开始监听客户端发过来的连接请求。此称为应用程序被动打开（等到客户端连接请求）
3. **SYN_SENT**：第一次握手发生阶段，客户端发起连接。客户端调用 connect，发送 SYN 给服务器端，然后进入 SYN_SENT 状态，等待服务器端确认（三次握手中的第二个报文）。如果服务器端不能连接，则直接进入CLOSED状态
4. **SYN_RCVD**：第二次握手发生阶段，跟 3 对应，这里是服务器端接收到了客户端的 SYN，此时服务器由 LISTEN 进入 SYN_RCVD状态，同时服务器端回应一个 ACK，然后再发送一个 SYN 即 SYN+ACK 给客户端。状态图中还描绘了这样一种情况，当客户端在发送 SYN 的同时也收到服务器端的 SYN请求，即两个同时发起连接请求，那么客户端就会从 SYN_SENT 转换到 SYN_REVD 状态
5. **ESTABLISHED**：第三次握手发生阶段，客户端接收到服务器端的 ACK 包（ACK，SYN）之后，也会发送一个 ACK 确认包，客户端进入 ESTABLISHED 状态，表明客户端这边已经准备好，但TCP 需要两端都准备好才可以进行数据传输。服务器端收到客户端的 ACK 之后会从 SYN_RCVD 状态转移到 ESTABLISHED 状态，表明服务器端也准备好进行数据传输了。这样客户端和服务器端都是 ESTABLISHED 状态，就可以进行后面的数据传输了。所以 ESTABLISHED 也可以说是一个数据传送状态

下面看看TCP四次挥手过程的状态变迁

1. **FIN_WAIT_1**：第一次挥手。主动关闭的一方（执行主动关闭的一方既可以是客户端，也可以是服务器端，这里以客户端执行主动关闭为例），终止连接时，发送 FIN 给对方，然后等待对方返回 ACK 。调用 close() 第一次挥手就进入此状态
2. **CLOSE_WAIT**：接收到FIN 之后，被动关闭的一方进入此状态。具体动作是接收到 FIN，同时发送 ACK。之所以叫 CLOSE_WAIT 可以理解为被动关闭的一方此时正在等待上层应用程序发出关闭连接指令。TCP关闭是全双工过程，这里客户端执行了主动关闭，被动方服务器端接收到FIN 后也需要调用 close 关闭，这个 CLOSE_WAIT 就是处于这个状态，等待发送 FIN，发送了FIN 则进入 LAST_ACK 状态
3. **FIN_WAIT_2**：主动端（这里是客户端）先执行主动关闭发送FIN，然后接收到被动方返回的 ACK 后进入此状态
4. **LAST_ACK**：被动方（服务器端）发起关闭请求，由状态2 进入此状态，具体动作是发送 FIN给对方，同时在接收到ACK 时进入CLOSED状态
5. **CLOSING**：两边同时发起关闭请求时（即主动方发送FIN，等待被动方返回ACK，同时被动方也发送了FIN，主动方接收到了FIN之后，发送ACK给被动方），主动方会由FIN_WAIT_1 进入此状态，等待被动方返回ACK
6. **TIME_WAIT**：从状态变迁图会看到，四次挥手操作最后都会经过这样一个状态然后进入CLOSED状态

| 状态            | **描述**                                               |
| --------------- | ------------------------------------------------------ |
| **CLOSED**      | 阻塞或关闭状态，表示主机当前没有正在传输或者建立的链接 |
| **LISTEN**      | 监听状态，表示服务器做好准备，等待建立传输链接         |
| **SYN RECV**    | 收到第一次的传输请求，还未进行确认                     |
| **SYN SENT**    | 发送完第一个SYN报文，等待收到确认                      |
| **ESTABLISHED** | 链接正常建立之后进入数据传输阶段                       |
| **FIN WAIT1**   | 主动发送第一个FIN报文之后进入该状态                    |
| **FIN WAIT2**   | 已经收到第一个FIN的确认信号，等待对方发送关闭请求      |
| **TIMED WAIT**  | 完成双向链接关闭，等待分组消失                         |
| **CLOSING**     | 双方同时关闭请求，等待对方确认时                       |
| **CLOSE WAIT**  | 收到对方的关闭请求并进行确认进入该状态                 |
| **LAST ACK**    | 等待最后一次确认关闭的报文                             |

## 1.13 简述 TCP 慢启动

- **慢启动**(Slow Start)：是传输控制协议（TCP）使用的一种阻塞控制机制。慢启动也叫做指数增长期。慢启动是指每次TCP接收窗口收到确认时都会增长。增加的大小就是已确认段的数目。这种情况一直保持到要么没有收到一些段，要么窗口大小到达预先定义的阈值。如果发生丢失事件，TCP就认为这是网络阻塞，就会采取措施减轻网络拥挤。一旦发生丢失事件或者到达阈值，TCP就会进入线性增长阶段。这时，每经过一个RTT窗口增长一个段

## 1.14 简述TCP 如何保证有序

- 主机每次发送数据时，TCP就给每个数据包分配一个序列号并且在一个特定的时间内等待接收主机对分配的这个序列号进行确认，如果发送主机在一个特定时间内没有收到接收主机的确认，则发送主机会重传此数据包。接收主机利用序列号对接收的数据进行确认，以便检测对方发送的数据是否有丢失或者乱序等，接收主机一旦收到已经顺序化的数据，它就将这些数据按正确的顺序重组成数据流并传递到高层进行处理。

- 具体步骤如下：

  1. 为了保证数据包的可靠传递，发送方必须把已发送的数据包保留在缓冲区

  2. 并为每个已发送的数据包启动一个超时定时器
  3. 如在定时器超时之前收到了对方发来的应答信息(可能是对本包的应答，也可以是对本包后续包的应答)，则释放该数据包占用的缓冲区

  4. 否则，重传该数据包，直到收到应答或重传次数超过规定的最大次数为止
  5. 接收方收到数据包后，先进行CRC校验，如果正确则把数据交给上层协议，然后给发送方发送一个累计应答包，表明该数据已收到，如果接收方正好也有数据要发给发送方，应答包也可方在数据包中捎带过去

## 1.15 TCP 常见的拥塞控制算法有哪些(重点)

1. TCP Tahoe/Reno

   **最初的实现，包括慢启动、拥塞避免两个部分**。基于重传超时（retransmission timeout/RTO）和重复确认为条件判断是否发生了丢包。两者的区别在于：Tahoe算法下如果收到三次重复确认，就进入快重传立即重发丢失的数据包，同时将慢启动阈值设置为当前拥塞窗口的一半，将拥塞窗口设置为1MSS，进入慢启动状态；而Reno算法如果收到三次重复确认，就进入快重传，但不进入慢启动状态，而是直接将拥塞窗口减半，进入拥塞控制阶段，这称为“快恢复”

   而Tahoe和Reno算法在出现RTO时的措施一致，都是将拥塞窗口降为1个MSS，然后进入慢启动阶段。

2. TCP BBR（Bottleneck Bandwidth and Round-trip propagation time）

   BBR是由Google设计，于2016年发布的拥塞算法。以往大部分拥塞算法是基于丢包来作为降低传输速率的信号，而BBR则基于模型主动探测。该算法使用网络最近出站数据分组当时的最大带宽和往返时间来建立网络的显式模型。数据包传输的每个累积或选择性确认用于生成记录在数据包传输过程和确认返回期间的时间内所传送数据量的采样率。该算法认为随着网络接口控制器逐渐进入千兆速度时，分组丢失不应该被认为是识别拥塞的主要决定因素，所以基于模型的拥塞控制算法能有更高的吞吐量和更低的延迟，可以用BBR来替代其他流行的拥塞算法，例如CUBIC

## 1.16 简述TCP超时重传

TCP可靠性中最重要的一个机制是**处理数据超时和重传**。TCP协议要求在发送端每发送一个报文段，就启动一个定时器并等待确认信息。接收端成功接收新数据后返回确认信息。若在定时器超时前数据未能被确认，TCP就认为报文段中的数据已丢失或损坏，需要对报文段中的数据重新组织和重传

## 1.17 简述TCP可靠性保证

TCP主要提供**检验和、序列号/确认应答、超时重传、最大消息长度、滑动窗口控制**等方法实现了可靠性传输

### 1.17.1 检验和

- 通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃TCP段，重新发送。TCP在计算检验和时，会在TCP首部加上一个12字节的伪首部。检验和总共计算3部分：TCP首部、TCP数据、TCP伪首部

  ![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789359716/E2A285BCBCC6683F7C31D93A5F09949F)

### 1.17.2 序列号/确认应答

- 这个机制类似于问答的形式。比如在课堂上老师会问你“明白了吗？”，假如你没有隔一段时间没有回应或者你说不明白，那么老师就会重新讲一遍。其实计算机的确认应答机制也是一样的，发送端发送信息给接收端，接收端会回应一个包，这个包就是应答包。

  ![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789371852/CE928C6281EB9E5F1668C214E5F02161)

- 上述过程中，只要发送端有一个包传输，接收端没有回应确认包（ACK包），都会重发。或者接收端的应答包，发送端没有收到也会重发数据。这就可以保证数据的完整性。

### 1.17.3 超时重传

- 超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传。那么我们该如何确认这个时间值呢？

- 我们知道，一来一回的时间总是差不多的，都会有一个类似于平均值的概念。比如发送一个包到接收端收到这个包一共是0.5s，然后接收端回发一个确认包给发送端也要0.5s，这样的两个时间就是RTT（往返时间）。然后可能由于网络原因的问题，时间会有偏差，称为抖动（方差）。

- 从上面的介绍来看，超时重传的时间大概是比往返时间+抖动值还要稍大的时间。

  ![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789382645/DDF950D26A632C641D311664ECF40D20)

- 但是在重发的过程中，假如一个包经过多次的重发也没有收到对端的确认包，那么就会认为接收端异常，强制关闭连接。并且通知应用通信异常强行终止。

### 1.17.4 最大消息长度

- 在建立TCP连接的时候，双方约定一个最大的长度（MSS）作为发送的单位，重传的时候也是以这个单位来进行重传。理想的情况下是该长度的数据刚好不被网络层分块。

  ![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789391981/A059761D56E15A86C7ED6E638051FAF7)

### 1.17.5 滑动窗口控制

- 我们上面提到的超时重传的机制存在效率低下的问题，发送一个包到发送下一个包要经过一段时间才可以。所以我们就想着能不能不用等待确认包就发送下一个数据包呢？这就提出了一个滑动窗口的概念。

  ![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789403643/659C5AE5C8D84563CCA0D862ABFC4C52)窗口的大小就是在无需等待确认包的情况下，发送端还能发送的最大数据量。这个机制的实现就是使用了大量的缓冲区，通过对多个段进行确认应答的功能。通过下一次的确认包可以判断接收端是否已经接收到了数据，如果已经接收了就从缓冲区里面删除数据。

- 在窗口之外的数据就是还未发送的和对端已经收到的数据。那么发送端是怎么样判断接收端有没有接收到数据呢？或者怎么知道需要重发的数据有哪些呢？通过下面这个图就知道了。

  ![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789413218/FD3C7C2A119E2714AB6CFBA2DD1256DC)

- 如上图，接收端在没有收到自己所期望的序列号数据之前，会对之前的数据进行重复确认。发送端在收到某个应答包之后，又连续3次收到同样的应答包，则数据已经丢失了，需要重发。

### 1.17.6 拥塞控制

- 窗口控制解决了 两台主机之间因传送速率而可能引起的丢包问题，在一方面保证了TCP数据传送的可靠性。然而如果网络非常拥堵，此时再发送数据就会加重网络负担，那么发送的数据段很可能超过了最大生存时间也没有到达接收方，就会产生丢包问题。为此TCP引入慢启动机制，先发出少量数据，就像探路一样，先摸清当前的网络拥堵状态后，再决定按照多大的速度传送数据。
- 发送开始时定义拥塞窗口大小为1；每次收到一个ACK应答，拥塞窗口加1；而在每次发送数据时，发送窗口取拥塞窗口与接送段接收窗口最小者。
- 慢启动：在启动初期以指数增长方式增长；设置一个慢启动的阈值，当以指数增长达到阈值时就停止指数增长，按照线性增长方式增加至拥塞窗口；线性增长达到网络拥塞时立即把拥塞窗口置回1，进行新一轮的“慢启动”，同时新一轮的阈值变为原来的一半。

![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789424239/B41F05347CDECC894EF3DE02D1909879)

## 1.18 简述 TCP 滑动窗口以及重传机制

1. 滑动窗口协议是传输层进行流控的一种措施，接收方通过通告发送方自己的窗口大小，从而控制发送方的发送速度，从而达到防止发送方发送速度过快而导致自己被淹没的目的

   TCP的滑动窗口解决了端到端的流量控制问题，允许接受方对传输进行限制，直到它拥有足够的缓冲空间来容纳更多的数据

2. TCP在发送数据时会设置一个计时器，若到计时器超时仍未收到数据确认信息，则会引发相应的超时或基于计时器的重传操作，计时器超时称为**重传超时（RTO）** 。另一种方式的重传称为快速重传，通常发生在没有延时的情况下。若TCP累积确认无法返回新的ACK，或者当ACK包含的选择确认信息（SACK）表明出现失序报文时，快速重传会推断出现丢包，需要重传。

## 1.19 滑动窗口过小怎么办

- 我们可以假设窗口的大小是1，也是就每次只能发送一个数据，并且发送方只有接受方对这个数据进行确认以后才能发送下一个数据。**如果说窗口过小，那么当传输比较大的数据的时候需要不停的对数据进行确认，这个时候就会造成很大的延迟**

## 1.20 如果三次握手时候每次握手信息对方没收到会怎么样，分情况介绍

1. 如果第一次握手消息丢失，那么请求方不会得到ack消息，超时后进行重传

2. 如果第二次握手消息丢失，那么请求方不会得到ack消息，超时后进行重传

3. 如果第三次握手消息丢失，那么Server 端该TCP连接的状态为SYN_RECV,并且会根据 TCP的超时重传机制，会等待3秒、6秒、12秒后重新发送SYN+ACK包，以便Client重新发送ACK包。而Server重发SYN+ACK包的次数，可以设置/proc/sys/net/ipv4/tcp_synack_retries修改，默认值为5.如果重发指定次数之后，仍然未收到 client 的ACK应答，那么一段时间后，Server自动关闭这个连接

   client 一般是通过 connect() 函数来连接服务器的，而connect()是在 TCP的三次握手的第二次握手完成后就成功返回值。也就是说 client 在接收到 SYN+ACK包，它的TCP连接状态就为 established （已连接），表示该连接已经建立。那么如果 第三次握手中的ACK包丢失的情况下，Client 向 server端发送数据，Server端将以 RST包响应，方能感知到Server的错误

## 1.21 简述TCP的TIME_WAIT，为什么需要有这个状态

1. TIME_WAIT状态也成为2MSL等待状态。**每个具体TCP实现必须选择一个报文段最大生存时间MSL(Maximum Segment Lifetime)，它是任何报文段被丢弃前在网络内的最长时间**。这个时间是有限的，因为**TCP报文段以IP数据报在网络内传输，而IP数据报则有限制其生存时间的TTL字段**

   对一个具体实现所给定的MSL值，处理的原则是：当TCP执行一个主动关闭，并发回最后一个ACK，该连接必须在TIME_WAIT状态停留的时间为2倍的MSL。这样**可让TCP再次发送最后的ACK以防这个ACK丢失**(另一端超时并重发最后的FIN)

   这种2MSL等待的另一个结果是这个TCP连接在2MSL等待期间，定义这个连接的插口（客户的IP地址和端口号，服务器的IP地址和端口号）不能再被使用。这个连接只能在2MSL结束后才能再被使用

2. 理论上，四个报文都发送完毕，就可以直接进入CLOSE状态，但是可能网络是不可靠的，有可能最后一个ACK丢失。所以**TIME_WAIT状态就是用来重发可能丢失的ACK报文**

## 1.22 简述什么是 MSL，为什么客户端连接要等待2MSL的时间才能完全关闭

1. MSL是Maximum Segment Lifetime的英文缩写，可译为**“最长报文段寿命”，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃**
2. 为**保证客户端发送的最后一个ACK报文段能够到达服务器**。因为这个ACK有可能丢失，从而导致处在LAST-ACK状态的服务器收不到对FIN-ACK的确认报文。服务器会超时重传这个FIN-ACK，接着客户端再重传一次确认，重新启动时间等待计时器。最后客户端和服务器都能正常的关闭。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态

- 两个理由：

  - **保证客户端发送的最后一个ACK报文段能够到达服务端**

    这个ACK报文段有可能丢失，使得处于LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认，服务端超时重传FIN+ACK报文段，而客户端能在2MSL时间内收到这个重传的FIN+ACK报文段，接着客户端重传一次确认，重新启动2MSL计时器，最后客户端和服务端都进入到CLOSED状态，若客户端在TIME-WAIT状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到服务端重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则服务端无法正常进入到CLOSED状态

  - **防止“已失效的连接请求报文段”出现在本连接中**

    客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段

## 1.23 什么是 SYN flood，如何防止这类攻击？

**参考回答**

1. SYN Flood是当前最流行的DoS（拒绝服务攻击）与DDoS(分布式拒绝服务攻击)的方式之一，这是一种利用TCP协议缺陷，发送大量伪造的TCP连接请求，使被攻击方资源耗尽（CPU满负荷或内存不足)的攻击方式

2. 有以下三种方法预防或响应网络上的DDoS攻击：

   - **从互联网服务提供商(ISP)购买服务**

   许多互联网服务提供商(ISP)提供DDoS缓解服务，但是当企业网络受到攻击时，企业需要向互联网服务提供商(ISP)报告事件以开始缓解。这种策略称为“**清洁管道**”，在互联网服务提供商(ISP)收取服务费用时很受欢迎，但在缓解措施开始之前，通常会导致30到60分钟的网络延迟

   - **保留在内部并自己解决**

   企业可以使用入侵防御系统/防火墙技术和专用于防御DDoS攻击的专用硬件来实现内部预防和响应DDoS攻击。不幸的是，受影响的流量已经在网络上消耗宝贵的带宽。这使得该方法最适合在托管设施中配备设备的企业，在这些企业中，流量是通过交叉连接到达互联网服务提供商(ISP)，从而保护流向企业其他部门的下游带宽

   - **使用内容分发网络(CDN)**

   由于IT团队可以将基础设施置于内容分发网络(CDN)后面，因此这种方法可以最大程度地减少对企业网络基础设施的攻击。这些网络庞大而多样，如果组织订阅DNS和DDoS缓解措施，则它们可以保护电子商务站点以及企业本身。

## 1.24 什么是 TCP 粘包和拆包？

- TCP是个“流”协议，所谓流，就是没有界限的一串数据。大家可以想想河里的流水，是连成一片的，其间并没有分界线。TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行包的划分，所以在业务上认为，**一个完整的包可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是所谓的TCP粘包和拆包问题**

假设客户端分别发送了两个数据包D1和D2给服务端，由于服务端一次读取到的字节数是不确定的，故可能存在以下4种情况：

- 服务端分两次读取到两个独立的数据包，分别是D1和D2，没有粘包和拆包
- **服务端一次接收到两个数据包，D1和D2粘合在一起**，被称为**TCP粘包**
- **服务端分两次读取到两个数据包，第一次读取到完整的D1包和D2包的部分内容，第二次读取到D2包的剩余内容**，这被称为**TCP拆包**
- 服务端分两次读取到两个数据包，第一次读取到D1包的部分内容D1_1，第二次读取到D1包的剩余内容D1_2和D2包的整包

如果此时服务端TCP接收滑窗非常小，而数据包D1和D2比较大，很有可能会发生第五种可能，即服务端分多次才能将D1和D2包接收完全，期间发生多次拆包

## 1.25 TCP与UDP在网络协议中的哪一层，他们之间有什么区别(重点)

TCP和UDP协议都是**传输层**协议。二者的区别主要有：

1 **基于连接vs无连接**

- **TCP是面向连接的协议**
- **UDP是无连接的协议**。UDP更加适合**消息的多播发布，从单个点向多个点传输消息**

2 **可靠性**

- TCP提供交付保证，传输过程中丢失，将会重发
- UDP是不可靠的，不提供任何交付保证。(网游和视频的丢包情况)

3 **有序性**

- TCP保证消息的有序性，即使到达客户端顺序不同，TCP也会排序
- UDP不提供有序性保证

4 **数据边界**

- **TCP不保存数据边界**

  虽然**TCP将在收集所有字节之后生成一个完整的消息**，但是这些信息在传给传输给接受端之前将储存在TCP缓冲区，以确保更好的使用网络带宽

- **UDP保证**

  **UDP中，数据包单独发送的，只有当他们到达时，才会再次集成**。包有明确的界限来哪些包已经收到，这意味着在消息发送后，在接收器接口将会有一个读操作，来生成一个完整的消息

5 **速度**

- TCP速度慢
- UDP速度快。应用在在线视频媒体，电视广播和多人在线游戏。

6 **发送消耗**

- TCP是重量级

- UDP是轻量级

  因为UDP传输的信息中不承担任何间接创造连接，保证交货或秩序的的信息。这也反映在用于报头大小

7 **报头大小**

- **TCP头大**

  **一个TCP数据包报头的大小是20字节**。TCP报头中包含序列号，ACK号，数据偏移量，保留，控制位，窗口，紧急指针，可选项，填充项，校验位，源端口和目的端口

- **UDP头小**

  **UDP数据报报头是8个字节**。而UDP报头只包含长度，源端口号，目的端口，和校验和

8 **拥塞或流控制**

- **TCP有流量控制**

  在任何用户数据可以被发送之前，TCP需要三数据包来设置一个套接字连接。TCP处理的可靠性和拥塞控制

- **UDP不能进行流量控制**

9 **应用**

- 由于TCP提供可靠交付和有序性的保证，它是最适合需要**高可靠并且对传输时间要求不高的应用**
- **UDP是更适合的应用程序需要快速，高效的传输的应用**，如游戏
- UDP是无状态的性质，在服务器端需要对大量客户端产生的少量请求进行应答的应用中是非常有用的
- 实践中，TCP被用于金融领域，如FIX协议是一种基于TCP的协议，而UDP是大量使用在游戏和娱乐场所

10 **上层使用的协议**

- **基于TCP协议**：Telnet，FTP以及SMTP协议
- **基于UDP协议**：DHCP、DNS、SNMP、TFTP、BOOTP

## 1.26 从系统层面上，UDP如何保证尽量可靠？

- **UDP仅提供最基本的数据传输功能**，至于传输时连接的建立和断开、传输可靠性的保证这些UDP统统不关心，而是把这些问题抛给UDP上层的应用层程序去处理，自己仅提供传输层协议的最基本功能

- 最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理，可靠UDP的简单设计：

  **添加seq/ack机制，确保数据发送到对端**

  **添加发送和接收缓冲区，主要是用户超时重传**

  **添加超时重传机制**

## 1.27 TCP的keepalive，以及和 HTTP 的 keepalive的区别？

**参考回答**

- **HTTP Keep-Alive**

在http早期，每个http请求都要求打开一个tpc socket连接，并且使用一次之后就断开这个tcp连接。使用keep-alive可以改善这种状态，即在一次TCP连接中可以持续发送多份数据而不会断开连接。通过使用keep-alive机制，可以减少tcp连接建立次数，也意味着可以减少TIME_WAIT状态连接，以此提高性能和提高httpd服务器的吞吐率(更少的tcp连接意味着更少的系统内核调用,socket的accept()和close()调用)。但是，keep-alive并不是免费的午餐，长时间的tcp连接容易导致系统资源无效占用。配置不当的keep-alive，有时比重复利用连接带来的损失还更大。所以，正确地设置keep-alive timeout时间非常重要

- **TCP KEEPALIVE**

链接建立之后，如果应用程序或者上层协议一直不发送数据，或者隔很长时间才发送一次数据，当链接很久没有数据报文传输时如何去确定对方还在线，到底是掉线还是确实没有数据传输，链接还需不需要保持，这种情况在TCP协议设计中是需要考虑到的。TCP协议通过一种巧妙的方式去解决这个问题，当超过一段时间之后，TCP自动发送一个数据为空的报文给对方，如果对方回应这个报文，说明对方还在线，链接可以继续保持，如果对方没有报文返回，并且重试多次之后则认为链接丢失，没有必要保持链接

- TCP的keepalive机制和HTTP的keep-alive机制是说的完全不同的两个东西，tcp的keepalive是在ESTABLISH状态的时候，双方如何检测连接的可用行。而http的keep-alive说的是如何避免进行重复的TCP三次握手和四次挥手的环节

## 1.28 简述TCP协议的延迟ACK和累计应答

1. **延迟应答**：TCP在接收到对端的报文后，并不会立即发送ack，而是等待一段时间发送ack，**以便将ack和要发送的数据一块发送**。当然ack不能无限延长，否则对端会认为包超时而造成报文重传。**linux采用动态调节算法来确定延时的时间**
2. **累计应答**：为了保证**顺序性**，每一个包都有一个**ID**(序号)，在建立连接的时候，会商定起始的ID是多少，然后按照ID一个个发送。而为了保证不丢包，对应发送的包都要进行应答，但不是一个个应答，而是会**应答某个之前的ID**，该模式称为**累计应答**

## 1.29 TCP 如何加速一个大文件的传输

1. **建连优化**：TCP 在建立连接时，如果丢包，会进入重试，重试时间是 1s、2s、4s、8s 的指数递增间隔，缩短定时器可以让 TCP 在丢包环境建连时间更快，非常适用于高并发短连接的业务场景。
2. **平滑发包**：在 RTT 内均匀发包，规避微分时间内的流量突发，尽量避免瞬间拥塞
3. **丢包预判**：有些网络的丢包是有规律性的，例如每隔一段时间出现一次丢包，例如每次丢包都连续丢几个等，如果程序能自动发现这个规律（有些不明显），就可以针对性提前多发数据，减少重传时间、提高有效发包率
4. **RTO 探测**：若始终收不到 ACK 报文，则需要触发 RTO 定时器。RTO 定时器一般都时间非常长，会浪费很多等待时间，而且一旦 RTO，CWND 就会骤降（标准 TCP），因此利用 Probe 提前与 RTO 去试探，可以规避由于 ACK 报文丢失而导致的速度下降问题
5. **带宽评估**：通过单位时间内收到的 ACK 或 SACK 信息可以得知客户端有效接收速率，通过这个速率可以更合理的控制发包速度
6. **带宽争抢**：有些场景（例如合租）是大家互相挤占带宽的，假如你和室友各 1Mbps 的速度看电影，会把 2Mbps 出口占满，而如果一共有 3 个人看，则每人只能分到 1/3。若此时你的流量流量达到 2Mbps，而他俩还都是 1Mbps，则你至少仍可以分到 2/(2+1+1) * 2Mbps = 1Mbps 的 50% 的带宽，甚至更多，代价就是服务器侧的出口流量加大，增加成本。(TCP 优化的本质就是用带宽换用户体验感)

## 1.30 服务器怎么判断客户端断开连接

1. 检测连接是否丢失的方法大致有两种：**keepalive**和**heart-beat**
2. **tcp内部机制**：采用keepalive，它会先要求此连接一定时间没有活动(一般是几个小时)，然后发出数据段，经过多次尝试后(每次尝试之间也有时间间隔)，如果仍没有响应，则判断连接中断。整个**周期需要很长**的时间
3. **应用层实现**：一个简单的heart-beat实现一般测试连接是否中断采用的时间间隔都比较短，可以**很快的决定连接是否中断**。并且，由于是在应用层实现，因为可以自行决定当判断连接中断后应该采取的行为，而keepalive在判断连接失败后只会将连接丢弃

## 1.31 端到端，点到点的区别

### 1.31.1 端对端

- **端到端通信是针对传输层来说的，传输层为网络中的主机提供端到端的通信**。因为无论tcp还是udp协议，都要负责把上层交付的数据从发送端传输到接收端，不论其中间跨越多少节点。只不过tcp比较可靠而udp不可靠而已。所以**称之为端到端，就是从发送端到接收端**
- 它是一个网络连接，指的是在数据传输之前，在发送端与接收端之间（忽略中间有多少设备）为数据的传输建立一条链路，链路建立以后，发送端就可以发送数据，知道数据发送完毕，接收端确认接收成功。 也就是说在数据传输之前，先为数据的传输开辟一条通道，然后在进行传输。从发送端发出数据到接收端接收完毕，结束
- **端到端通信建立在点到点通信的基础之上，它是由一段段的点到点通信信道构成的，是比点到点通信更高一级的通信方式，完成应用程序(进程)之间的通信**

端到端的优点：

- 链路建立之后，发送端知道接收端一定能收到，而且经过中间交换设备时不需要进行存储转发，因此传输延迟小。

端到端传输的缺点：

- 直到接收端收到数据为止，发送端的设备一直要参与传输。如果整个传输的延迟很长，那么对发送端的设备造成很大的浪费
- 如果接收设备关机或故障，那么端到端传输不可能实现

### 1.31.2 点对点

- 点到点通信是针对数据链路层或网络层来说的，因为数据链路层只负责直接相连的两个节点之间的通信，一个节点的数据链路层接受ip层数据并封装之后，就把数据帧从链路上发送到与其相邻的下一个节点。 点对点是基于MAC地址和或者IP地址，是指一个设备发数据给与该这边直接连接的其他设备，这台设备又在合适的时候将数据传递给与它相连的下一个设备，通过一台一台直接相连的设备把数据传递到接收端
- 直接相连的节点对等实体的通信叫点到点通信。它只提供一台机器到另一台机器之间的通信，不会涉及到程序或进程的概念。同时点到点通信并不能保证数据传输的可靠性，也不能说明源主机与目的主机之间是哪两个进程在通信
- 由物理层、数据链路层和网络层组成的通信子网为网络环境中的主机提供点到点的服务 

点到点的优点：

- 发送端设备送出数据后，它的任务已经完成，不需要参与整个传输过程，这样不会浪费发送端设备的资源
- 即使接收端设备关机或故障，点到点传输也可以采用存储转发技术进行缓冲

点到点的缺点：

- 点到点传输的缺点是发送端发出数据后，不知道接收端能否收到或何时能收到数据
- 在一个网络系统的不同分层中，可能用到端到端传输，也可能用到点到点传输。如Internet网，IP及以下各层采用点到点传输，4层以上采用端到端传输

## 1.32 浏览器从输入URL到展现页面的全过程(重点)

- 输入地址
- 浏览器查找域名的 IP 地址
- 浏览器向 web 服务器发送一个 HTTP 请求
- 服务器的永久重定向响应
- 服务器处理请求
- 服务器返回一个 HTTP 响应
- 浏览器显示 HTML
- 浏览器发送请求获取嵌入在 HTML 中的资源（如图片、音频、视频、CSS、JS等等）

## 1.33 简述 HTTP 和 HTTPS 的区别？

- **HTTP**：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准(TCP)，**用于从WWW服务器传输超文本到本地浏览器的传输协议，可以使浏览器更加高效，使网络传输减少**。HTTP是应用层，TCP是传输层
- **HTTPS**：以安全为目标的HTTP通道，是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL
- HTTPS协议的主要作用可以分为两种：**一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性**

HTTP与HTTPS的区别

- https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用
- **http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议**
- http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443
- http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全

## 1.34 HTTP中的 referer 头的作用

1. HTTP Referer是header的一部分，当浏览器向web服务器发送请求的时候，一般会带上Referer，告诉服务器该网页是从哪个页面链接过来的，服务器因此可以获得一些信息用于处理

2. **防盗链**

   假如在[www.google.com](https://www.nowcoder.com/issue/www.google.com)里有一个[www.baidu.com]链接，那么点击进入这个`[www.baidu.com]，它的header信息里就有：Referer= [http://www.google.com](http://www.google.com/)

   只允许我本身的网站访问本身的图片服务器，假如域是[www.google.com](http://www.google.com/)，那么图片服务器每次取到Referer来判断一下域名是不是[www.google.com](http://www.google.com/)，如果是就继续访问，不是就拦截

   将这个http请求发给服务器后，如果服务器要求必须是某个地址或者某几个地址才能访问，而你发送的referer不符合他的要求，就会拦截或者跳转到他要求的地址，然后再通过这个地址进行访问

3. **防止恶意请求**

   比如静态请求是\*.html结尾的，动态请求是\*.shtml，那么由此可以这么用，所有的*.shtml请求，必须Referer为我自己的网站

4. **空Referer**

   **定义**：Referer头部的内容为空，或者，一个HTTP请求中根本不包含Referer头部（一个请求并不是由链接触发产生的）

   直接在浏览器的地址栏中输入一个资源的URL地址，那么这种请求是不会包含Referer字段的，因为这是一个“凭空产生”的HTTP请求，并不是从一个地方链接过去的

   那么在防盗链设置中，允许空Referer和不允许空Referer有什么区别？

   允许Referer为空，意味着你允许比如浏览器直接访问

5. **防御CSRF**

   比对HTTP 请求的来源地址，如果Referer中的地址是安全可信任的地址，那么就放行

## 1.35 HTTP 的方法有哪些

- **GET**： 用于请求访问已经被URI(统一资源标识符)识别的资源，可以通过URL传参给服务器
- **POST**：用于传输信息给服务器，主要功能与GET方法类似，但一般推荐使用POST方式
- **PUT**： 传输文件，报文主体中包含文件内容，保存到对应URI位置
- **HEAD**： 获得报文首部，与GET方法类似，只是不返回报文主体，一般用于验证URI是否有效
- **DELETE**：删除文件，与PUT方法相反，删除对应URI位置的文件
- **OPTIONS**：查询相应URI支持的HTTP方法

## 1.36 简述HTTP 1.0，1.1，2.0主要区别

http/1.0 :

1. 默认不支持长连接，需要设置keep-alive参数指定
2. 强缓存expired、协商缓存last-modified\if-modified-since 有一定的缺陷

http 1.1 :

1. 默认长连接(keep-alive)，http请求可以复用Tcp连接，但是同一时间只能对应一个http请求(http请求在一个Tcp中是串行的)
2. 增加了强缓存cache-control、协商缓存etag\if-none-match 是对http/1 缓存的优化

http/2.0 :

1. 多路复用，一个Tcp中多个http请求是并行的 (雪碧图、多域名散列等优化手段http/2中将变得多余)
2. 二进制格式编码传输
3. 使用HPACK算法做header压缩
4. 服务端推送

## 1.37 HTTP 常见的响应状态码及其含义

- **200** : 从状态码发出的请求被服务器正常处理
- **204** : 服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分【即没有内容】
- **206** : 部分的内容（如：客户端进行了范围请求，但是服务器成功执行了这部分的干请求）
- **301** : 跳转，代表永久性重定向（请求的资源已被分配了新的URI，以后已使用资源，现在设置了URI）
- **302** : 临时性重定向（请求的资源已经分配了新的URI，希望用户本次能够使用新的URI来进行访问）
- **303** : 由于请求对应的资源存在的另一个URI（因使用get方法，定向获取请求的资源）
- **304** : 客户端发送附带条件的请求时，服务器端允许请求访问资源，但因发生请求未满足条件的情况后，直接返回了 304
- **307** : 临时重定向【该状态码与302有着相同的含义】
- **400** : 请求报文中存在语法错误（当错误方式时，需修改请求的内容后，再次发送请求）
- **401** : 发送的请求需要有通过HTTP认证的认证信息
- **403** : 对请求资源的访问被服务器拒绝了
- **404** : 服务器上无法找到请求的资源
- **500** : 服务器端在执行请求时发生了错误
- **503** : 服务器暂时处于超负载或者是正在进行停机维护，现在无法处理请求

- **1XX : 信息类状态码(表示接收请求状态处理)**
- **2XX : 成功状态码(表示请求正常处理完毕)**
- **3XX : 重定向(表示需要进行附加操作，已完成请求)**
- **4XX : 客户端错误(表示服务器无法处理请求)**
- **5XX : 服务器错误状态码(表示服务器处理请求的时候出错)**

## 1.38 GET请求和POST请求的区别

- GET请求在URL中传送的参数是有长度限制的，而POST没有
- GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息
- GET参数通过URL传递，POST放在Request body中
- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留
- GET请求只能进行url编码，而POST支持多种编码方式
- GET请求会被浏览器主动cache，而POST不会，除非手动设置
- GET产生的URL地址可以被Bookmark，而POST不可以
- GET在浏览器回退时是无害的，而POST会再次提交请求

## 1.39 Cookie 和 Session 的关系和区别是什么

1. Cookie与Session都是会话的一种方式。它们的典型使用场景比如“购物车”，当你点击下单按钮时，服务端并不清楚具体用户的具体操作，为了标识并跟踪该用户，了解购物车中有几样物品，服务端通过为该用户创建Cookie/Session来获取这些信息
2. **cookie数据存放在客户的浏览器上，session数据放在服务器上**
3. cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗，考虑到安全应当使用session
4. session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能  考虑到减轻服务器性能方面，应当使用COOKIE
5. 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie

## 1.40 简述 HTTPS 的加密与认证过程

- 客户端在浏览器中输入一个https网址，然后连接到server的443端口 采用https协议的server必须有一套数字证书（一套公钥和密钥） 首先server将证书（公钥）传送到客户端 客户端解析证书，验证成功，则生成一个随机数（私钥），并用证书将该随机数加密后传回server server用密钥解密后，获得这个随机值，然后将要传输的信息和私钥通过某种算法混合在一起（加密）传到客户端 客户端用之前的生成的随机数（私钥）解密服务器端传来的信息
- 首先浏览器会从内置的证书列表中索引，找到服务器下发证书对应的机构，如果没有找到，此时就会提示用户该证书是不是由权威机构颁发，是不可信任的。如果查到了对应的机构，则取出该机构颁发的公钥
- 用机构的证书公钥解密得到证书的内容和证书签名，内容包括网站的网址、网站的公钥、证书的有效期等。浏览器会先验证证书签名的合法性。签名通过后，浏览器验证证书记录的网址是否和当前网址是一致的，不一致会提示用户。如果网址一致会检查证书有效期，证书过期了也会提示用户。这些都通过认证时，浏览器就可以安全使用证书中的网站公钥

# 2 C++八股

## 2.1 OSI 七层协议模型  

- OSI 模型（Open System Interconnection Model）是⼀个由 ISO 提出得到概念模型，试图提供⼀个使各种不同的的计算机和⽹络在世界范围内实现互联的标准框架
- 虽然OSI参考模型在实际中的应⽤意义并不是很⼤，但是它对于理解网络协议内部的运作很有帮助，为学习⽹络协议提供⼀个很好的参考。它将计算机网络体系结构划分为7层，每层都为上⼀层提供良好的接⼝。以下将具体介绍各层结构及功能

## 2.2 七层功能

- **物理层**

物理层(Physical Layer)确保原始的数据可在各种物理媒体上传输。在这⼀层上⾯规定激活，维持，关闭通信端点之间的机械性，电气特性，功能特性，为上层协议提供了⼀个传输数据的物理媒体，这⼀层传输的是 bit 流

- **数据链路层**

数据链路层(Data Link Layer)在不可靠的物理介质上提供可靠的传输。该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。这⼀层中将 bit 流封装成frame 帧

- **网络层**

⽹络层(Network Layer)负责对子网间的数据包进⾏路由选择。此外网络层还可以实现**拥塞控制、网际互连**等功能。在这⼀层，数据的单位称为数据包(packet)

- **传输层**

传输层是第⼀个端到端，即主机到主机的层次。传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输。此外，传输层还要处理端到端的差错控制和流量控制问题。在这⼀层，数据的单位称为数据(segment)

- **会话层**

这⼀层管理主机之间的会话进程，即负责建⽴、管理、终⽌进程之间的会话。会话层还利⽤在数据中插⼊校验点来实现数据的同步，访问验证和会话管理在内的建⽴和维护应⽤之间通信的机制。如服务器验证⽤户登录便是由会话层完成的。使通信会话在通信失效时从校验点继续恢复通信。 **⽐如说建立会话，如 session 认证、断点续传**

- **表示层**

这⼀层主要解决⽤户信息的语法表示问题。它将欲交换的数据从适合于某⼀⽤户的抽象语法，转换为适合于OSI系统内部使⽤的传送语法。即提供格式化的表示和转换数据服务。数据的压缩和解压缩， 加密和解密等⼯作都由表示层负责。比如说图像、视频编码解，数据加密

- **应用层**

这⼀层为操作系统或网络应用程序提供访问网络服务的接⼝

## 2.3 七层传输协议、传输单元、主要功能性设备比较  

| 名称        |                     传输协议                      |     传输单元     |            主要功能设备/接⼝            |
| ----------- | :-----------------------------------------------: | :--------------: | :-------------------------------------: |
| 物理层      |             IEEE 802.1A、 IEEE 802.2              | bit-flow ⽐特流  | 光纤，双绞线，中继器， 集线器，⽹线接⼝ |
| 数据链 路层 | ARP、 MAC、 FDDI、 Ethernet、 Arpanet、 PPP、 PDN |     frame 帧     |            ⽹桥、⼆层交换机             |
| ⽹络层      |              IP、 ICMP、 ARP、 RARP               | 数据包（packet） |           路由器、三层交换机            |
| 传输层      |                     TCP、 UDP                     | Segment/Datagram |               四层交换机                |
| 会话层      |                    SMTP、 DNS                     |       报⽂       |                   QoS                   |
| 表示层      |                   Telnet、 SNMP                   |       报⽂       |                    -                    |
| 应⽤层      |         FTP、 TFTP、 Telnet、 HTTP、 DNS          |       报⽂       |                    -                    |

## 2.4 描述TCP头部

- **序号**(32bit)：传输⽅向上字节流的字节编号。初始时序号会被设置⼀个随机的初始值(ISN)，之后每次发送数据时，序号值 = ISN + 数据在整个字节流中的偏移。假设A -> B且ISN = 1024，第⼀段数据512字节已经到B，则第⼆段数据发送时序号为1024 + 512。用于解决网络包乱序问题
- **确认号**(32bit)：接收方对发送方TCP报文段的响应，其值是收到的序号值 + 1
- **首部长**(4bit)：标识首部有多少个4字节 * 首部⻓，最大为15，即60字节
- **标志位**(6bit)
  URG：标志紧急指针是否有效
  ACK：标志确认号是否有效(确认报⽂段)，用于解决丢包问题
  PSH：提示接收端立即从缓冲读走数据
  RST：表示要求对方重新建立连接(复位报文段)
  SYN：表示请求建立一个连接(连接报⽂段)
  FIN：表示关闭连接(断开报⽂段)
- **窗口**(16bit)：接收窗口。用于告知对方(发送方)本方的缓冲还能接收多少字节数据。用于解决流控
- **校验和**(16bit)：接收端⽤CRC检验整个报⽂段有⽆损坏

## 2.5 TCP三次握手和挥手

### 2.5.1 三次握手过程

- 第⼀次：客户端发含SYN位，SEQ_NUM = S的包到服务器。(客 -> SYN_SEND)
- 第⼆次：服务器发含ACK，SYN位且ACK_NUM = S + 1， SEQ_NUM = P的包到客户机。(服 ->SYN_RECV)
- 第三次：客户机发送含ACK位， ACK_NUM = P + 1的包到服务器。(客 -> ESTABLISH，服 ->ESTABLISH)

### 2.5.2 四次挥手过程

- 第⼀次：客户机发含FIN位， SEQ = Q的包到服务器。(客 -> FIN_WAIT_1)
- 第⼆次：服务器发送含ACK且ACK_NUM = Q + 1的包到服务器。(服 -> CLOSE_WAIT，客 ->FIN_WAIT_2)。此处有等待

- 第三次：服务器发送含FIN且SEQ_NUM = R的包到客户机。(服 -> LAST_ACK，客 -> TIME_WAIT)。此处有等待
- 第四次：客户机发送最后⼀个含有ACK位且ACK_NUM = R + 1的包到客户机。(服 -> CLOSED)

### 2.5.3 为什么握手是三次，挥手是四次

- 对于握手：握手只需要确认双方通信时的初始化序号，保证通信不会乱序。(第三次握手必要性：假设服务端的确认丢失，连接并未断开，客户机超时重发连接请求，这样服务器会对同⼀个客户机保持多个连接，造成资源浪费)
- 对于挥手：TCP是双⼯的，所以发送方和接收方都需要FIN和ACK。只不过有⼀方是被动的，所以看上去就成4次挥手

### 2.5.4 TCP连接状态

- CLOSED：初始状态
- LISTEN：服务器处于监听状态
- SYN_SEND：客户端socket执行CONNECT连接，发送SYN包，进⼊此状态
- SYN_RECV：服务端收到SYN包并发送服务端SYN包，进入此状态
- ESTABLISH：表示连接建立。客户端发送最后⼀个ACK包后进⼊此状态，服务端接收到ACK包后进⼊此状态
- FIN_WAIT_1：终⽌连接的⼀方(通常是客户机)发送FIN报⽂后进⼊。等待对⽅FIN
- CLOSE_WAIT：(假设服务器)接收到客户机FIN包之后等待关闭的阶段。在接收到对方的FIN包之后，自然是需要立即回复ACK包的，表示已经知道断开请求。但是本⽅是否立即断开连接(发送FIN包)取决于是否还有数据需要发送给客户端，若有，则在发送FIN包之前均为此状态
- FIN_WAIT_2：此时是半连接状态，即有⼀⽅要求关闭连接，等待另⼀⽅关闭。客户端接收到服务器的ACK包，但并没有⽴即接收到服务端的FIN包，进⼊FIN_WAIT_2状态
- LAST_ACK：服务端发动最后的FIN包，等待最后的客户端ACK响应，进⼊此状态
- TIME_WAIT：客户端收到服务端的FIN包，并立即发出ACK包做最后的确认，在此之后的2MSL时间称为TIME_WAIT状态

### 2.5.5 解释FIN_WAIT_2，CLOSE_WAIT状态和TIME_WAIT状态？

- **FIN_WAIT_2状态**

1. 半关闭状态

2. 发送断开请求一方还有接收数据能力，但已经没有发送数据能力

- **CLOSE_WAIT状态**

1. 被动关闭连接⼀方接收到FIN包会⽴即回应ACK包表示已接收到断开请求

2. 被动关闭连接⼀方如果还有剩余数据要发送就会进⼊CLOSED_WAIT状态

- **TIME_WAIT状态**

1. ⼜叫2MSL等待状态
2. 如果客户端直接进⼊CLOSED状态，如果服务端没有接收到最后⼀次ACK包会在超时之后重新再发FIN包，此时因为客户端已经CLOSED，所以服务端就不会收到ACK⽽是收到RST。所以TIME_WAIT状态⽬的是防⽌最后⼀次握⼿数据没有到达对方而触发重传FIN准备
3. 在2MSL时间内，同⼀个socket不能再被使用，否则有可能会和旧连接数据混淆(如果新连接和旧连接的socket相同的话)

### 2.5.6 解释RTO， RTT和超时重传？

- 超时重传：发送端发送报⽂后若⻓时间未收到确认的报⽂则需要重发该报⽂。可能有以下⼏种情况：

1. 发送的数据没能到达接收端，所以对⽅没有响应
2. 接收端接收到数据，但是ACK报⽂在返回过程中丢失
3. 接收端拒绝或丢弃数据

- RTO：从上⼀次发送数据，因为⻓期没有收到ACK响应，到下⼀次重发之间的时间。就是重传间隔

1. 通常每次重传RTO是前⼀次重传间隔的两倍，计量单位通常是RTT。例： 1RTT， 2RTT， 4RTT，8RTT......

2. 重传次数到达上限之后停止重传

- RTT：数据从发送到接收到对⽅响应之间的时间间隔，即数据报在⽹络中⼀个往返⽤时。大小不稳定
- ⽬的是接收⽅通过TCP头窗⼝字段告知发送⽅本⽅可接收的最⼤数据量，⽤以解决发送速率过快导致接收⽅不能接收的问题。所以流量控制是点对点控制
- TCP是双⼯协议，双⽅可以同时通信，所以发送⽅接收⽅各⾃维护⼀个发送窗和接收窗

1. 发送窗：⽤来限制发送⽅可以发送的数据大小，其中发送窗⼝的⼤⼩由接收端返回的TCP报⽂段中窗⼝字段来控制，接收⽅通过此字段告知发送⽅⾃⼰的缓冲(受系统、硬件等限制)大小
2. 接收窗：⽤来标记可以接收的数据大小

- TCP是流数据，发送出去的数据流可以被分为以下四部分：已发送且被确认部分 | 已发送未被确认部分 | 未发送但可发送部分 | 不可发送部分，其中发送窗 = 已发送未确认部分 + 未发但可发送部分。接收到的数据流可分为：已接收 | 未接收但准备接收 | 未接收不准备接收。接收窗 = 未接收但准备接收部分
- 发送窗内数据只有当接收到接收端某段发送数据的ACK响应时才移动发送窗，左边缘紧贴刚被确认的数据。接收窗也只有接收到数据且最左侧连续时才移动接收窗口

### 2.5.7 拥塞控制原理

- 拥塞控制⽬的是防⽌数据被过多注⽹络中导致⽹络资源（路由器、交换机等）过载。因为拥塞控制涉及⽹络链路全局，所以属于全局控制。控制拥塞使⽤拥塞窗⼝
- TCP拥塞控制算法

1. **慢开始 & 拥塞避免**：先试探⽹络拥塞程度再逐渐增⼤拥塞窗口。每次收到确认后拥塞窗⼝翻倍，直到达到阀值ssthresh，这部分是慢开始过程。达到阀值后每次以⼀个MSS为单位增⻓拥塞窗⼝⼤⼩，当发⽣拥塞(超时未收到确认)，将阀值减为原先⼀半，继续执⾏线性增加，这个过程为拥塞避免
2. **快速重传 & 快速恢复**：略
3. **最终拥塞窗⼝会收敛于稳定值**  

## 2.6 如何区分流量控制和拥塞控制

- 流量控制属于通信双⽅协商；拥塞控制涉及通信链路全局
- 流量控制需要通信双⽅各维护⼀个发送窗、⼀个接收窗，对任意⼀⽅，接收窗⼤⼩由⾃身决定，发送窗⼤⼩由接收⽅响应的TCP报⽂段中窗⼝值确定；拥塞控制的拥塞窗⼝⼤⼩变化由试探性发送⼀定数据量数据探查⽹络状况后⽽⾃适应调整
- 实际最终发送窗⼝ = min{流控发送窗⼝，拥塞窗⼝}

## 2.7 TCP如何提供可靠数据传输的？

- **建⽴连接(标志位)**：通信前确认通信实体存在
- **序号机制(序号、确认号)**：确保数据是按序、完整到达
- **数据校验(校验和)**：CRC校验全部数据
- **超时重传(定时器)**：保证因链路故障未能到达数据能够被多次重发 
- **窗口机制(窗口)**：提供流量控制，避免过量发送
- **拥塞控制**：同上  

